{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7664f9ec-06bf-4a1a-ae5f-bcbc01a314b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langgraph\n",
      "  Downloading langgraph-0.0.55-py3-none-any.whl (84 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting uuid6<2025.0.0,>=2024.1.12\n",
      "  Downloading uuid6-2024.1.12-py3-none-any.whl (6.4 kB)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.2 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from langgraph) (0.2.0)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2->langgraph) (0.1.59)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2->langgraph) (23.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2->langgraph) (6.0.1)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2->langgraph) (8.3.0)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2->langgraph) (2.5.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2->langgraph) (1.33)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2->langgraph) (2.1)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.3,>=0.2->langgraph) (2.31.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.3,>=0.2->langgraph) (3.10.3)\n",
      "Requirement already satisfied: pydantic-core==2.14.3 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2->langgraph) (2.14.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2->langgraph) (4.7.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2->langgraph) (0.6.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.3,>=0.2->langgraph) (2023.11.17)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.3,>=0.2->langgraph) (1.26.18)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.3,>=0.2->langgraph) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.3,>=0.2->langgraph) (3.4)\n",
      "Installing collected packages: uuid6, langgraph\n",
      "Successfully installed langgraph-0.0.55 uuid6-2024.1.12\n"
     ]
    }
   ],
   "source": [
    "!pip install langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "287188d2-cd08-419a-90f3-63c9e75bff4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_openai\n",
      "  Downloading langchain_openai-0.1.7-py3-none-any.whl (34 kB)\n",
      "Collecting openai<2.0.0,>=1.24.0\n",
      "  Downloading openai-1.30.3-py3-none-any.whl (320 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.6/320.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: langchain-core<0.3,>=0.1.46 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from langchain_openai) (0.2.0)\n",
      "Collecting tiktoken<1,>=0.7\n",
      "  Downloading tiktoken-0.7.0-cp310-cp310-macosx_11_0_arm64.whl (906 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.8/906.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from langchain-core<0.3,>=0.1.46->langchain_openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from langchain-core<0.3,>=0.1.46->langchain_openai) (0.1.59)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from langchain-core<0.3,>=0.1.46->langchain_openai) (6.0.1)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from langchain-core<0.3,>=0.1.46->langchain_openai) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from langchain-core<0.3,>=0.1.46->langchain_openai) (2.5.1)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from langchain-core<0.3,>=0.1.46->langchain_openai) (8.3.0)\n",
      "Collecting distro<2,>=1.7.0\n",
      "  Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: tqdm>4 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (4.65.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (4.7.1)\n",
      "Collecting httpx<1,>=0.23.0\n",
      "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sniffio in /Users/kossee/anaconda3/lib/python3.10/site-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (1.2.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain_openai) (2023.12.25)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain_openai) (2.31.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.24.0->langchain_openai) (3.4)\n",
      "Requirement already satisfied: certifi in /Users/kossee/anaconda3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain_openai) (2023.11.17)\n",
      "Collecting httpcore==1.*\n",
      "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting h11<0.15,>=0.13\n",
      "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.46->langchain_openai) (2.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.3,>=0.1.46->langchain_openai) (3.10.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.46->langchain_openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.3 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.46->langchain_openai) (2.14.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (1.26.18)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.0.4)\n",
      "Installing collected packages: h11, distro, tiktoken, httpcore, httpx, openai, langchain_openai\n",
      "Successfully installed distro-1.9.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 langchain_openai-0.1.7 openai-1.30.3 tiktoken-0.7.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7a3ccdf-cd77-4c68-ae0d-743a71e29cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.graph import END, MessageGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b529bdc6-884b-4ae7-b7de-dd6511725621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /Users/kossee/anaconda3/lib/python3.10/site-packages (0.2.0)\n",
      "Requirement already satisfied: langgraph in /Users/kossee/anaconda3/lib/python3.10/site-packages (0.0.55)\n",
      "Requirement already satisfied: langchain_openai in /Users/kossee/anaconda3/lib/python3.10/site-packages (0.1.7)\n",
      "Collecting langchainhub\n",
      "  Downloading langchainhub-0.1.16-py3-none-any.whl (4.8 kB)\n",
      "Requirement already satisfied: langsmith in /Users/kossee/anaconda3/lib/python3.10/site-packages (0.1.59)\n",
      "Collecting duckduckgo-search\n",
      "  Downloading duckduckgo_search-6.1.0-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/kossee/anaconda3/lib/python3.10/site-packages (4.12.2)\n",
      "Collecting gradio\n",
      "  Downloading gradio-4.31.5-py3-none-any.whl (12.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from langchain) (8.3.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from langchain) (0.6.6)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.0 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from langchain) (0.2.0)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from langchain) (3.9.1)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from langchain) (0.2.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from langchain) (2.0.30)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from langchain) (1.26.0)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from langchain) (2.5.1)\n",
      "Requirement already satisfied: uuid6<2025.0.0,>=2024.1.12 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from langgraph) (2024.1.12)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.24.0 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from langchain_openai) (1.30.3)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from langchain_openai) (0.7.0)\n",
      "Collecting types-requests<3.0.0.0,>=2.31.0.2\n",
      "  Downloading types_requests-2.32.0.20240523-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from langsmith) (3.10.3)\n",
      "Requirement already satisfied: click>=8.1.7 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from duckduckgo-search) (8.1.7)\n",
      "Collecting pyreqwest-impersonate>=0.4.5\n",
      "  Downloading pyreqwest_impersonate-0.4.5-cp38-abi3-macosx_11_0_arm64.whl (2.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: soupsieve>1.2 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.3 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from gradio) (0.19.4)\n",
      "Collecting importlib-resources<7.0,>=1.3\n",
      "  Downloading importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from gradio) (4.7.1)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from gradio) (2.1.1)\n",
      "Collecting typer<1.0,>=0.12\n",
      "  Downloading typer-0.12.3-py3-none-any.whl (47 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fastapi\n",
      "  Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting ruff>=0.2.2\n",
      "  Downloading ruff-0.4.5-py3-none-macosx_11_0_arm64.whl (8.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: matplotlib~=3.0 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from gradio) (3.7.2)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from gradio) (2.1.1)\n",
      "Collecting uvicorn>=0.14.0\n",
      "  Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2<4.0 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from gradio) (3.1.2)\n",
      "Collecting gradio-client==0.16.4\n",
      "  Downloading gradio_client-0.16.4-py3-none-any.whl (315 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.9/315.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting altair<6.0,>=4.2.0\n",
      "  Downloading altair-5.3.0-py3-none-any.whl (857 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m857.8/857.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /Users/kossee/anaconda3/lib/python3.10/site-packages (from gradio) (23.2)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from gradio) (0.27.0)\n",
      "Collecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from gradio) (10.0.1)\n",
      "Collecting aiofiles<24.0,>=22.0\n",
      "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Collecting ffmpy\n",
      "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting semantic-version~=2.0\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting tomlkit==0.12.0\n",
      "  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
      "Collecting urllib3~=2.0\n",
      "  Downloading urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting python-multipart>=0.0.9\n",
      "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
      "Collecting websockets<12.0,>=10.0\n",
      "  Downloading websockets-11.0.3-cp310-cp310-macosx_11_0_arm64.whl (121 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.0/121.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec in /Users/kossee/anaconda3/lib/python3.10/site-packages (from gradio-client==0.16.4->gradio) (2023.10.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Collecting toolz\n",
      "  Downloading toolz-0.12.1-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jsonschema>=3.0 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio) (4.17.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/kossee/anaconda3/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (1.0.5)\n",
      "Requirement already satisfied: anyio in /Users/kossee/anaconda3/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (3.5.0)\n",
      "Requirement already satisfied: sniffio in /Users/kossee/anaconda3/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (1.2.0)\n",
      "Requirement already satisfied: idna in /Users/kossee/anaconda3/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (3.4)\n",
      "Requirement already satisfied: certifi in /Users/kossee/anaconda3/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (2023.11.17)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->gradio) (4.65.0)\n",
      "Requirement already satisfied: filelock in /Users/kossee/anaconda3/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->gradio) (3.12.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.0->langchain) (1.33)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (0.11.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (1.0.5)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (3.0.9)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2023.3)\n",
      "Requirement already satisfied: pydantic-core==2.14.3 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.14.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain_openai) (2023.12.25)\n",
      "Collecting shellingham>=1.3.0\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Collecting rich>=10.11.0\n",
      "  Downloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from fastapi->gradio) (5.4.0)\n",
      "Collecting fastapi-cli>=0.0.2\n",
      "  Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
      "Collecting starlette<0.38.0,>=0.37.2\n",
      "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting typing-extensions~=4.0\n",
      "  Downloading typing_extensions-4.12.0-py3-none-any.whl (37 kB)\n",
      "Collecting email_validator>=2.0.0\n",
      "  Downloading email_validator-2.1.1-py3-none-any.whl (30 kB)\n",
      "Collecting dnspython>=2.0.0\n",
      "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jsonpointer>=1.9 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain) (2.1)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.15.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Collecting httptools>=0.5.0\n",
      "  Downloading httptools-0.6.1-cp310-cp310-macosx_10_9_universal2.whl (149 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.8/149.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting watchfiles>=0.13\n",
      "  Downloading watchfiles-0.21.0-cp310-cp310-macosx_11_0_arm64.whl (418 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m418.3/418.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting uvloop!=0.15.0,!=0.15.1,>=0.14.0\n",
      "  Downloading uvloop-0.19.0-cp310-cp310-macosx_10_9_universal2.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting python-dotenv>=0.13\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Collecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Building wheels for collected packages: ffmpy\n",
      "  Building wheel for ffmpy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5583 sha256=10ce3ee2d43c6bd6f42b60d947e130811436952b4bf06252f274e4e2c59f4825\n",
      "  Stored in directory: /Users/kossee/Library/Caches/pip/wheels/aa/aa/6f/aa192c329d49b2d65c988bca8fbb8f483259c82989d8d56610\n",
      "Successfully built ffmpy\n",
      "Installing collected packages: pydub, ffmpy, websockets, uvloop, urllib3, typing-extensions, toolz, tomlkit, shellingham, semantic-version, ruff, python-multipart, python-dotenv, pyreqwest-impersonate, mdurl, importlib-resources, httptools, dnspython, aiofiles, watchfiles, uvicorn, types-requests, starlette, markdown-it-py, email_validator, duckduckgo-search, rich, langchainhub, altair, typer, gradio-client, fastapi-cli, fastapi, gradio\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.18\n",
      "    Uninstalling urllib3-1.26.18:\n",
      "      Successfully uninstalled urllib3-1.26.18\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.7.1\n",
      "    Uninstalling typing_extensions-4.7.1:\n",
      "      Successfully uninstalled typing_extensions-4.7.1\n",
      "  Attempting uninstall: typer\n",
      "    Found existing installation: typer 0.9.0\n",
      "    Uninstalling typer-0.9.0:\n",
      "      Successfully uninstalled typer-0.9.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "conda-repo-cli 1.0.75 requires requests_mock, which is not installed.\n",
      "weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n",
      "spacy 3.7.2 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n",
      "conda-repo-cli 1.0.75 requires clyent==1.2.1, but you have clyent 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed aiofiles-23.2.1 altair-5.3.0 dnspython-2.6.1 duckduckgo-search-6.1.0 email_validator-2.1.1 fastapi-0.111.0 fastapi-cli-0.0.4 ffmpy-0.3.2 gradio-4.31.5 gradio-client-0.16.4 httptools-0.6.1 importlib-resources-6.4.0 langchainhub-0.1.16 markdown-it-py-3.0.0 mdurl-0.1.2 pydub-0.25.1 pyreqwest-impersonate-0.4.5 python-dotenv-1.0.1 python-multipart-0.0.9 rich-13.7.1 ruff-0.4.5 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.37.2 tomlkit-0.12.0 toolz-0.12.1 typer-0.12.3 types-requests-2.32.0.20240523 typing-extensions-4.12.0 urllib3-2.2.1 uvicorn-0.29.0 uvloop-0.19.0 watchfiles-0.21.0 websockets-11.0.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain langgraph langchain_openai langchainhub langsmith duckduckgo-search beautifulsoup4 gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc478629-1c42-4ca8-a996-6cbcf70854ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting typing_extensions==4.8.0\n",
      "  Using cached typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
      "Installing collected packages: typing_extensions\n",
      "  Attempting uninstall: typing_extensions\n",
      "    Found existing installation: typing_extensions 4.7.1\n",
      "    Uninstalling typing_extensions-4.7.1:\n",
      "      Successfully uninstalled typing_extensions-4.7.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spacy 3.7.2 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed typing_extensions-4.8.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install typing_extensions==4.8.0 --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0451ef5-2b6f-47c7-916b-a41e9402bbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81870701-76d2-4c5c-98c3-c0bdcdb52c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'supervisor': {'next': 'Web_Searcher'}}\n",
      "----\n",
      "{'Web_Searcher': {'messages': [HumanMessage(content='### AI Technology Trends in 2024: Summary and Insights\\n\\n#### Summary of Trends\\n\\n**1. Generative AI Evolution and Integration:** Generative AI, which saw explosive growth in public consciousness in recent years, is expected to be more practically integrated into everyday life and business operations by 2024. The evolution of generative AI is likened to the development of computers, predicting further progress in making powerful AI tools more accessible and efficient.\\n\\n**2. Multimodal AI:** AI models that process multiple types of data (text, images, audio) are becoming more prevalent, enhancing the versatility of AI applications. These models are expected to break new ground in natural language processing and computer vision, making AI interactions more intuitive and multi-dimensional.\\n\\n**3. Small(er) Language Models and Open Source Advancements:** There\\'s a shift towards smaller, more efficient AI models. Open source initiatives are driving the development of models that, despite their smaller size, are competitive with or even outperform their larger counterparts in specific tasks. This trend democratizes AI, allowing more entities to develop and utilize powerful AI tools.\\n\\n**4. AI Governance and Ethics:** As AI becomes more embedded in society, the focus on governance, ethics, and regulation intensifies. Efforts to make AI more trustworthy, sustainable, and accessible are gaining momentum, with a particular emphasis on addressing the ethical implications of AI technology.\\n\\n**5. Customized Enterprise AI and Shadow AI:** Enterprises are moving towards customized AI solutions tailored to specific needs, leveraging advancements in AI for more targeted applications. Concurrently, the phenomenon of \"shadow AI\" highlights the growing use of AI tools by employees without formal approval, posing challenges in governance and security.\\n\\n**6. Talent Demand in AI and Machine Learning:** The demand for skilled professionals in AI and machine learning continues to rise. Organizations are seeking talent capable of bridging the gap between AI theory and practical application, emphasizing the importance of skills in AI programming, data analysis, and machine learning operations.\\n\\n#### Insights for Each Trend\\n\\n1. **Generative AI Evolution and Integration:** \\n    - **Insight:** Businesses and researchers are increasingly finding ways to leverage generative AI for more than just novelty, integrating these technologies into functional, everyday tools and processes. As AI becomes a regular feature in business applications, the focus will likely shift to refining user experience and expanding the scope of tasks AI can perform autonomously.\\n\\n2. **Multimodal AI:** \\n    - **Insight:** The rise of multimodal AI signifies a step towards more natural human-computer interaction, where users can communicate with AI in various formats. This trend could revolutionize customer service, education, and entertainment, providing richer, more engaging experiences.\\n\\n3. **Small(er) Language Models and Open Source Advancements:** \\n    - **Insight:** The shift towards smaller AI models and open source projects could democratize AI, allowing startups and smaller companies to innovate and compete with tech giants. This trend might also encourage more community-driven development and faster innovation cycles in AI technologies.\\n\\n4. **AI Governance and Ethics:** \\n    - **Insight:** As AI technologies become more pervasive, establishing robust governance frameworks and ethical guidelines will be crucial to ensure their responsible use. This trend underscores the importance of transparency, accountability, and public trust in AI development and deployment.\\n\\n5. **Customized Enterprise AI and Shadow AI:** \\n    - **Insight:** The move towards customized AI solutions reflects the growing need for AI that aligns closely with specific business objectives and operations. However, the emergence of shadow AI highlights the challenges in balancing innovation with regulatory compliance and security. Organizations will need to develop strategies to harness the benefits of AI while mitigating risks.\\n\\n6. **Talent Demand in AI and Machine Learning:** \\n    - **Insight:** The increasing need for AI and machine learning talent emphasizes the critical role of human expertise in shaping the future of AI. As AI technologies evolve, there will be a growing demand for professionals who can not only develop AI models but also integrate them into real-world applications, underscoring the need for ongoing education and training in this rapidly changing field.\\n\\nThese insights suggest that while AI technology continues to advance rapidly, the focus is shifting towards practical applications, ethical considerations, and the human element in AI development and use. As we head into 2024, these trends are likely to shape the trajectory of AI technology and its impact on society.', name='Web_Searcher')]}}\n",
      "----\n",
      "{'supervisor': {'next': 'Insight_Researcher'}}\n",
      "----\n",
      "{'Insight_Researcher': {'messages': [HumanMessage(content=\"Based on the provided content, here are the insights identified for each of the AI technology trends expected to influence the landscape in 2024:\\n\\n1. **Generative AI Evolution and Integration:**\\n    - Generative AI's integration into daily and business applications is turning AI from a novelty into a fundamental tool. This trend suggests a shift towards making these technologies more user-friendly and expanding their applications, potentially transforming how businesses operate and innovate.\\n\\n2. **Multimodal AI:**\\n    - The development of multimodal AI models points towards more natural and intuitive interactions between humans and computers. By processing diverse types of data, these AI systems could significantly enhance experiences across various domains such as customer service, education, and entertainment, making digital interactions more engaging and efficient.\\n\\n3. **Small(er) Language Models and Open Source Advancements:**\\n    - The trend towards smaller, more efficient, and open-sourced AI models indicates a democratization of AI technology. This shift could level the playing field for smaller entities, fostering innovation and competition in the tech industry. It also suggests a move towards more collaborative, community-driven development efforts in the AI field.\\n\\n4. **AI Governance and Ethics:**\\n    - The increasing focus on AI governance and ethics highlights the growing recognition of the importance of responsible AI use. This trend underscores the necessity for transparent, accountable AI systems and points towards a future where ethical considerations are central to AI development and deployment, aiming to build public trust and sustainable AI practices.\\n\\n5. **Customized Enterprise AI and Shadow AI:**\\n    - The move towards customized AI solutions tailored to specific enterprise needs reflects the growing maturity of AI technology and its application in business. However, the rise of shadow AI poses governance and security challenges, indicating a need for organizations to balance innovation with oversight, potentially leading to new strategies for managing and integrating AI tools.\\n\\n6. **Talent Demand in AI and Machine Learning:**\\n    - The continuous demand for skilled AI and machine learning professionals emphasizes the importance of human capital in the AI industry. This trend points towards a future where expertise in AI development and application becomes increasingly valuable, highlighting the need for education and training programs to prepare the workforce for the evolving demands of the AI field.\\n\\nThese insights underscore the multifaceted impact of AI technology trends on society, industry, and the workforce. As AI continues to evolve, these trends suggest a complex interplay between technological innovation, ethical considerations, and the need for skilled professionals to drive the responsible and effective use of AI.\", name='Insight_Researcher')]}}\n",
      "----\n",
      "{'supervisor': {'next': 'FINISH'}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import functools, operator, requests, os, json\n",
    "from bs4 import BeautifulSoup\n",
    "from duckduckgo_search import DDGS\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import Annotated, Any, Dict, List, Optional, Sequence, TypedDict\n",
    "import gradio as gr\n",
    "\n",
    "# Set environment variables\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"testare_agenti\"\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4-turbo-preview\")\n",
    "\n",
    "@tool(\"internet_search\", return_direct=False)\n",
    "def internet_search(query: str) -> str:\n",
    "    \"\"\"Searches the internet using DuckDuckGo.\"\"\"\n",
    "    with DDGS() as ddgs:\n",
    "        results = [r for r in ddgs.text(query, max_results=5)]\n",
    "        return results if results else \"No results found.\"\n",
    "\n",
    "@tool(\"process_content\", return_direct=False)\n",
    "def process_content(url: str) -> str:\n",
    "    \"\"\"Processes content from a webpage.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    return soup.get_text()\n",
    "\n",
    "tools = [internet_search, process_content]\n",
    "\n",
    "def create_agent(llm: ChatOpenAI, tools: list, system_prompt: str):\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ])\n",
    "    agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "    executor = AgentExecutor(agent=agent, tools=tools)\n",
    "    return executor\n",
    "\n",
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    return {\"messages\": [HumanMessage(content=result[\"output\"], name=name)]}\n",
    "\n",
    "\n",
    "members = [\"Web_Searcher\", \"Insight_Researcher\"]\n",
    "system_prompt = (\n",
    "    \"As a supervisor, your role is to oversee a dialogue between these\"\n",
    "    \" workers: {members}. Based on the user's request,\"\n",
    "    \" determine which worker should take the next action. Each worker is responsible for\"\n",
    "    \" executing a specific task and reporting back their findings and progress. Once all tasks are complete,\"\n",
    "    \" indicate with 'FINISH'.\"\n",
    ")\n",
    "\n",
    "options = [\"FINISH\"] + members\n",
    "function_def = {\n",
    "    \"name\": \"route\",\n",
    "    \"description\": \"Select the next role.\",\n",
    "    \"parameters\": {\n",
    "        \"title\": \"routeSchema\",\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\"next\": {\"title\": \"Next\", \"anyOf\": [{\"enum\": options}] }},\n",
    "        \"required\": [\"next\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    (\"system\", \"Given the conversation above, who should act next? Or should we FINISH? Select one of: {options}\"),\n",
    "]).partial(options=str(options), members=\", \".join(members))\n",
    "\n",
    "supervisor_chain = (prompt | llm.bind_functions(functions=[function_def], function_call=\"route\") | JsonOutputFunctionsParser())\n",
    "\n",
    "search_agent = create_agent(llm, tools, \"You are a web searcher. Search the internet for information.\")\n",
    "search_node = functools.partial(agent_node, agent=search_agent, name=\"Web_Searcher\")\n",
    "\n",
    "insights_research_agent = create_agent(llm, tools, \n",
    "        \"\"\"You are a Insight Researcher. Do step by step. \n",
    "        Based on the provided content first identify the list of topics,\n",
    "        then search internet for each topic one by one\n",
    "        and finally find insights for each topic one by one.\n",
    "        Include the insights and sources in the final response\n",
    "        \"\"\")\n",
    "insights_research_node = functools.partial(agent_node, agent=insights_research_agent, name=\"Insight_Researcher\")\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    next: str\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"Web_Searcher\", search_node)\n",
    "workflow.add_node(\"Insight_Researcher\", insights_research_node)\n",
    "workflow.add_node(\"supervisor\", supervisor_chain)\n",
    "\n",
    "for member in members:\n",
    "    workflow.add_edge(member, \"supervisor\")\n",
    "\n",
    "conditional_map = {k: k for k in members}\n",
    "conditional_map[\"FINISH\"] = END\n",
    "workflow.add_conditional_edges(\"supervisor\", lambda x: x[\"next\"], conditional_map)\n",
    "workflow.set_entry_point(\"supervisor\")\n",
    "\n",
    "graph = workflow.compile()\n",
    "\n",
    "for s in graph.stream({\n",
    "    \"messages\": [HumanMessage(content=\"\"\"Search for the latest AI technology trends in 2024,\n",
    "            summarize the content. After summarise pass it on to insight researcher\n",
    "            to provide insights for each topic\"\"\")]\n",
    "}):\n",
    "    if \"__end__\" not in s:\n",
    "        print(s)\n",
    "        print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fc66977-bd9e-4508-b118-3185829f66d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import functools, operator, requests, os, json\n",
    "from bs4 import BeautifulSoup\n",
    "from duckduckgo_search import DDGS\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import Annotated, Any, Dict, List, Optional, Sequence, TypedDict\n",
    "import gradio as gr\n",
    "import re \n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\*\\*(.*?)\\*\\*', r'\\1', text)\n",
    "    text = re.sub(r'#+ ', '', text)\n",
    "    text = text.replace('\\u20ac', 'EUR')\n",
    "    text = re.sub(r'\\n- ', '\\n• ', text)\n",
    "    text = re.sub(r'\\n\\s*\\n', '\\n\\n', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"LangGraph Research Agents\"\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4-turbo-preview\")\n",
    "\n",
    "@tool(\"internet_search\", return_direct=False)\n",
    "def internet_search(query: str) -> str:\n",
    "    \"\"\"Searches the internet using DuckDuckGo.\"\"\"\n",
    "    with DDGS() as ddgs:\n",
    "        results = [r for r in ddgs.text(query, max_results=5)]\n",
    "        return results if results else \"No results found.\"\n",
    "\n",
    "@tool(\"process_content\", return_direct=False)\n",
    "def process_content(url: str) -> str:\n",
    "    \"\"\"Processes content from a webpage.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    return soup.get_text()\n",
    "\n",
    "tools = [internet_search, process_content]\n",
    "\n",
    "\n",
    "def create_agent(llm: ChatOpenAI, tools: list, system_prompt: str):\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ])\n",
    "    agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "    executor = AgentExecutor(agent=agent, tools=tools)\n",
    "    return executor\n",
    "\n",
    "\n",
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    return {\"messages\": [HumanMessage(content=result[\"output\"], name=name)]}\n",
    "\n",
    "members = [\"Web_Searcher\", \"Insight_Researcher\"]\n",
    "system_prompt = (\n",
    "    \"As a supervisor, your role is to oversee a dialogue between these\"\n",
    "    \" workers: {members}. Based on the user's request,\"\n",
    "    \" determine which worker should take the next action. Each worker is responsible for\"\n",
    "    \" executing a specific task and reporting back their findings and progress. Once all tasks are complete,\"\n",
    "    \" indicate with 'FINISH'.\"\n",
    ")\n",
    "\n",
    "options = [\"FINISH\"] + members\n",
    "function_def = {\n",
    "    \"name\": \"route\",\n",
    "    \"description\": \"Select the next role.\",\n",
    "    \"parameters\": {\n",
    "        \"title\": \"routeSchema\",\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\"next\": {\"title\": \"Next\", \"anyOf\": [{\"enum\": options}] }},\n",
    "        \"required\": [\"next\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    (\"system\", \"Given the conversation above, who should act next? Or should we FINISH? Select one of: {options}\"),\n",
    "]).partial(options=str(options), members=\", \".join(members))\n",
    "\n",
    "supervisor_chain = (prompt | llm.bind_functions(functions=[function_def], function_call=\"route\") | JsonOutputFunctionsParser())\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    next: str\n",
    "\n",
    "search_agent = create_agent(llm, tools, \"You are a web searcher. Search the internet for information.\")\n",
    "search_node = functools.partial(agent_node, agent=search_agent, name=\"Web_Searcher\")\n",
    "\n",
    "insights_research_agent = create_agent(llm, tools, \n",
    "        \"\"\"You are a Insight Researcher. Do step by step. \n",
    "        Based on the provided content first identify the list of topics,\n",
    "        then search internet for each topic one by one\n",
    "        and finally find insights for each topic one by one.\n",
    "        Include the insights and sources in the final response\n",
    "        \"\"\")\n",
    "insights_research_node = functools.partial(agent_node, agent=insights_research_agent, name=\"Insight_Researcher\")\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"Web_Searcher\", search_node)\n",
    "workflow.add_node(\"Insight_Researcher\", insights_research_node)\n",
    "workflow.add_node(\"supervisor\", supervisor_chain)\n",
    "\n",
    "for member in members:\n",
    "    workflow.add_edge(member, \"supervisor\")\n",
    "\n",
    "conditional_map = {k: k for k in members}\n",
    "conditional_map[\"FINISH\"] = END\n",
    "workflow.add_conditional_edges(\"supervisor\", lambda x: x[\"next\"], conditional_map)\n",
    "workflow.set_entry_point(\"supervisor\")\n",
    "\n",
    "graph = workflow.compile()\n",
    "\n",
    "def run_graph(input_message):\n",
    "    response = graph.invoke({\n",
    "        \"messages\": [HumanMessage(content=input_message)]\n",
    "    })\n",
    "    return json.dumps(preprocess_text(response['messages'][1].content), indent=2)\n",
    "\n",
    "inputs = gr.Textbox(lines=2, placeholder=\"Enter your query here...\")\n",
    "outputs = gr.Textbox()\n",
    "\n",
    "demo = gr.Interface(fn=run_graph, inputs=inputs, outputs=outputs)\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a06118de-b556-495c-8005-4db77fcb0928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import functools, operator, requests, os, json\n",
    "from bs4 import BeautifulSoup\n",
    "from duckduckgo_search import DDGS\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import Annotated, Any, Dict, List, Optional, Sequence, TypedDict\n",
    "import gradio as gr\n",
    "import re \n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\*\\*(.*?)\\*\\*', r'\\1', text)\n",
    "    text = re.sub(r'#+ ', '', text)\n",
    "    text = text.replace('\\u20ac', 'EUR')\n",
    "    text = re.sub(r'\\n- ', '\\n• ', text)\n",
    "    text = re.sub(r'\\n\\s*\\n', '\\n\\n', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"LangGraph Research Agents\"\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4-turbo-preview\")\n",
    "\n",
    "@tool(\"internet_search\", return_direct=False)\n",
    "def internet_search(query: str) -> str:\n",
    "    \"\"\"Searches the internet using DuckDuckGo.\"\"\"\n",
    "    with DDGS() as ddgs:\n",
    "        results = [r for r in ddgs.text(query, max_results=5)]\n",
    "        return results if results else \"No results found.\"\n",
    "\n",
    "@tool(\"process_content\", return_direct=False)\n",
    "def process_content(url: str) -> str:\n",
    "    \"\"\"Processes content from a webpage.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    return soup.get_text()\n",
    "\n",
    "tools = [internet_search, process_content]\n",
    "\n",
    "def create_agent(llm: ChatOpenAI, tools: list, system_prompt: str):\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ])\n",
    "    agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "    executor = AgentExecutor(agent=agent, tools=tools)\n",
    "    return executor\n",
    "\n",
    "\n",
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    return {\"messages\": [HumanMessage(content=result[\"output\"], name=name)]}\n",
    "\n",
    "members = [\"Web_Searcher\", \"Insight_Researcher\"]\n",
    "system_prompt = (\n",
    "    \"As a supervisor, your role is to oversee a dialogue between these\"\n",
    "    \" workers: {members}. Based on the user's request,\"\n",
    "    \" determine which worker should take the next action. Each worker is responsible for\"\n",
    "    \" executing a specific task and reporting back their findings and progress. Once all tasks are complete,\"\n",
    "    \" indicate with 'FINISH'.\"\n",
    ")\n",
    "\n",
    "options = [\"FINISH\"] + members\n",
    "function_def = {\n",
    "    \"name\": \"route\",\n",
    "    \"description\": \"Select the next role.\",\n",
    "    \"parameters\": {\n",
    "        \"title\": \"routeSchema\",\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\"next\": {\"title\": \"Next\", \"anyOf\": [{\"enum\": options}] }},\n",
    "        \"required\": [\"next\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    (\"system\", \"Given the conversation above, who should act next? Or should we FINISH? Select one of: {options}\"),\n",
    "]).partial(options=str(options), members=\", \".join(members))\n",
    "\n",
    "supervisor_chain = (prompt | llm.bind_functions(functions=[function_def], function_call=\"route\") | JsonOutputFunctionsParser())\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    next: str\n",
    "\n",
    "search_agent = create_agent(llm, tools, \"You are a web searcher. Search the internet for information.\")\n",
    "search_node = functools.partial(agent_node, agent=search_agent, name=\"Web_Searcher\")\n",
    "\n",
    "insights_research_agent = create_agent(llm, tools, \n",
    "        \"\"\"You are a Insight Researcher. Do step by step. \n",
    "        Based on the provided content first identify the list of topics,\n",
    "        then search internet for each topic one by one\n",
    "        and finally find insights for each topic one by one.\n",
    "        Include the insights and sources in the final response\n",
    "        \"\"\")\n",
    "insights_research_node = functools.partial(agent_node, agent=insights_research_agent, name=\"Insight_Researcher\")\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"Web_Searcher\", search_node)\n",
    "workflow.add_node(\"Insight_Researcher\", insights_research_node)\n",
    "workflow.add_node(\"supervisor\", supervisor_chain)\n",
    "\n",
    "for member in members:\n",
    "    workflow.add_edge(member, \"supervisor\")\n",
    "\n",
    "conditional_map = {k: k for k in members}\n",
    "conditional_map[\"FINISH\"] = END\n",
    "workflow.add_conditional_edges(\"supervisor\", lambda x: x[\"next\"], conditional_map)\n",
    "workflow.set_entry_point(\"supervisor\")\n",
    "\n",
    "graph = workflow.compile()\n",
    "\n",
    "def run_graph(input_message):\n",
    "    response = graph.invoke({\n",
    "        \"messages\": [HumanMessage(content=input_message)]\n",
    "    })\n",
    "    return json.dumps(preprocess_text(response['messages'][1].content), indent=2)\n",
    "\n",
    "inputs = gr.Textbox(lines=2, placeholder=\"Enter your query here...\")\n",
    "outputs = gr.Textbox()\n",
    "\n",
    "demo = gr.Interface(fn=run_graph, inputs=inputs, outputs=outputs)\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b46cf48-5cb5-42ba-8a06-eede10c96d10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28aa474d-3b5d-459d-b7fb-05449833d5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dumitrescustefan/bert-base-romanian-cased-v1 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7866\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import functools, operator, requests, os, json\n",
    "from bs4 import BeautifulSoup\n",
    "from duckduckgo_search import DDGS\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain.tools import tool\n",
    "from typing import Annotated, Any, Dict, List, Optional, Sequence, TypedDict\n",
    "import gradio as gr\n",
    "import re\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('dumitrescustefan/bert-base-romanian-cased-v1')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('dumitrescustefan/bert-base-romanian-cased-v1')\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"LangGraph Research Agents\"\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4-turbo-preview\")\n",
    "\n",
    "def replace_unicode_chars(text):\n",
    "    replacements = {\n",
    "        '\\\\u0219': 'ș', '\\\\u0218': 'Ș',\n",
    "        '\\\\u021b': 'ț', '\\\\u021a': 'Ț',\n",
    "        '\\\\u0103': 'ă', '\\\\u0102': 'Ă',\n",
    "        '\\\\u00ee': 'î', '\\\\u00ce': 'Î',\n",
    "        '\\\\u00e2': 'â', '\\\\u00c2': 'Â',\n",
    "        '\\\\u00e3': 'ã', '\\\\u00c3': 'Ã',\n",
    "        '\\\\u00e0': 'à', '\\\\u00c0': 'À',\n",
    "        '\\\\u00e9': 'é', '\\\\u00c9': 'É',\n",
    "        '\\\\\\\"': '\"'\n",
    "    }\n",
    "    \n",
    "    for unicode_char, romanian_char in replacements.items():\n",
    "        text = text.replace(unicode_char, romanian_char)\n",
    "    \n",
    "    return text\n",
    "\n",
    "@tool(\"verify_content\", return_direct=False)\n",
    "def detect_fake_news(text: str) -> str:\n",
    "    \"\"\"Uses a pretrained Romanian model to predict whether the text is likely to be fake news.\"\"\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        predictions = torch.sigmoid(outputs.logits)\n",
    "        fake_news_prob = predictions[:, 1].item()\n",
    "\n",
    "    if fake_news_prob > 0.5:\n",
    "        return f\"Posibil știri false (Confidență: {fake_news_prob:.2f})\"\n",
    "    else:\n",
    "        return \"Probabil de încredere\"\n",
    "\n",
    "@tool(\"internet_search\", return_direct=False)\n",
    "def internet_search(query: str) -> str:\n",
    "    \"\"\"Searches the internet using DuckDuckGo, focusing on Romanian sources.\"\"\"\n",
    "    with DDGS() as ddgs:\n",
    "        results = [r for r in ddgs.text(f\"{query} site:.ro\", max_results=5)]\n",
    "        return results if results else \"Niciun rezultat găsit.\"\n",
    "\n",
    "@tool(\"process_content\", return_direct=False)\n",
    "def process_content(url: str) -> str:\n",
    "    \"\"\"Processes content from a Romanian webpage.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    return soup.get_text()\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    next: str\n",
    "\n",
    "tools = [internet_search, process_content, detect_fake_news]\n",
    "\n",
    "def create_agent(llm, tools, system_prompt):\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ])\n",
    "    agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "    executor = AgentExecutor(agent=agent, tools=tools)\n",
    "    return executor\n",
    "\n",
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    return {\"messages\": [HumanMessage(content=result[\"output\"], name=name)]}\n",
    "\n",
    "members = [\"Web_Searcher\", \"Insight_Researcher\"]\n",
    "system_prompt = (\n",
    "    \"As a supervisor, your role is to oversee a dialogue between these workers: {members}. \"\n",
    "    \"Based on the user's request, determine which worker should take the next action. \"\n",
    "    \"Each worker is responsible for executing a specific task and reporting back their findings and progress. \"\n",
    "    \"Once all tasks are complete, indicate with 'FINISH'.\"\n",
    ")\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "search_agent = create_agent(llm, tools, \"You are a web searcher. Search the internet for information.\")\n",
    "search_node = functools.partial(agent_node, agent=search_agent, name=\"Web_Searcher\")\n",
    "insights_research_agent = create_agent(llm, tools, \"\"\"You are a Insight Researcher. Do step by step. \n",
    "        Based on the provided content first verify the authenticity of information,\n",
    "        then search internet for other news related to the one it was provided\n",
    "        and finally find insights so you can say if the original news is fake or not.\n",
    "        Include the insights and sources in the final response\n",
    "        \"\"\")\n",
    "\n",
    "insights_research_node = functools.partial(agent_node, agent=insights_research_agent, name=\"Insight_Researcher\")\n",
    "\n",
    "workflow.add_node(\"Web_Searcher\", search_node)\n",
    "workflow.add_node(\"Insight_Researcher\", insights_research_node)\n",
    "\n",
    "for member in members:\n",
    "    workflow.add_edge(member, \"supervisor\")\n",
    "\n",
    "conditional_map = {k: k for k in members}\n",
    "conditional_map[\"FINISH\"] = END\n",
    "workflow.add_conditional_edges(\"supervisor\", lambda x: x[\"next\"], conditional_map)\n",
    "workflow.set_entry_point(\"supervisor\")\n",
    "\n",
    "def run_graph(input_message):\n",
    "    response = graph.invoke({\n",
    "        \"messages\": [HumanMessage(content=input_message)]\n",
    "    })\n",
    "    return json.dumps(replace_unicode_chars(response['messages'][1].content), indent=2)\n",
    "\n",
    "inputs = gr.Textbox(lines=2, placeholder=\"Enter your query here...\")\n",
    "outputs = gr.Textbox()\n",
    "\n",
    "demo = gr.Interface(fn=run_graph, inputs=inputs, outputs=outputs)\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43e25c8-e794-49ec-88e4-9824ff4f26a5",
   "metadata": {},
   "source": [
    "### Intrebarea: Verifica daca este falsa stirea de pe site-ul acesta: https://www.nationalisti.ro/usr-militeaza-pentru-educatia-sexuala-in-scoli-ne-indoctrineaza-copiii-cu-propaganda-homosexuala/\n",
    "\n",
    "### Raspunsul:\n",
    "'Site-ul postat pare să promoveze o perspectivă extrem de critică față de educația sexuală în școli, prezentând-o într-o lumină negativă și acuzând USR de îndoctrinare cu \"propagandă homosexuală\". Totuși, informațiile disponibile din surse mai echilibrate și de încredere indică faptul că USR PLUS susține introducerea orelor de educație sexuală în școli ca un mijloc de a oferi tinerilor informații corecte și sănătoase despre sexualitate, sănătatea reproducerii și relații. Conform unui articol de pe [Europa Liberă](https://romania.europalibera.org/a/educatie-sexuala-in-scoli/31315070.html), liderul USR PLUS, Dan Barna, a catalogat drept iresponsabili pe care se opun acestei educații.\\n\\nÎn plus, cercetările indică un sprijin larg în rândul populației pentru introducerea educației sexuale în școli, cu un studiu arătând că peste 83% din respondenți susțin introducerea obligatorie a acestei materii ([EduPedu](https://www.edupedu.ro/cercetare-cu-privire-la-introducerea-educatiei-sexuale-in-scoli-peste-83-dintre-respondenti-sunt-pentru/)). De asemenea, Ministrul Educației, Sorin Cîmpeanu, a susținut introducerea acestei educații ca disciplină obligatorie, subliniind necesitatea unei abordări inteligente și adaptate realităților comunităților ([EduPedu](https://www.edupedu.ro/introducerea-educatiei-sexuale-in-scoli-ca-disciplina-obligatorie-sub-denumirea-de-educatie-sexuala-sustintuta-de-ministrul-educatiei-care-spune-ca-este-nevoie-si-de-educatie-parentala/)).\\n\\nPrin urmare, bazându-ne pe aceste surse, pare că stirea de pe site-ul menționat prezintă informații distorsionate și potențial înșelătoare despre poziția și intențiile USR în ceea ce privește educația sexuală în școli. Discursul promovat de site-ul respectiv pare să fie mai mult orientat spre propagandă decât spre o discuție obiectivă și informată despre subiect.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d555c42-8a1e-4762-8e50-4aba5c6e7e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Site-ul postat pare să promoveze o perspectivă extrem de critică față de educația sexuală în școli, prezentând-o într-o lumină negativă și acuzând USR de îndoctrinare cu \"propagandă homosexuală\". Totuși, informațiile disponibile din surse mai echilibrate și de încredere indică faptul că USR PLUS susține introducerea orelor de educație sexuală în școli ca un mijloc de a oferi tinerilor informații corecte și sănătoase despre sexualitate, sănătatea reproducerii și relații. Conform unui articol de pe [Europa Liberă](https://romania.europalibera.org/a/educatie-sexuala-in-scoli/31315070.html), liderul USR PLUS, Dan Barna, a catalogat drept iresponsabili pe care se opun acestei educații.\\n\\nÎn plus, cercetările indică un sprijin larg în rândul populației pentru introducerea educației sexuale în școli, cu un studiu arătând că peste 83% din respondenți susțin introducerea obligatorie a acestei materii ([EduPedu](https://www.edupedu.ro/cercetare-cu-privire-la-introducerea-educatiei-sexuale-in-scoli-peste-83-dintre-respondenti-sunt-pentru/)). De asemenea, Ministrul Educației, Sorin Cîmpeanu, a susținut introducerea acestei educații ca disciplină obligatorie, subliniind necesitatea unei abordări inteligente și adaptate realităților comunităților ([EduPedu](https://www.edupedu.ro/introducerea-educatiei-sexuale-in-scoli-ca-disciplina-obligatorie-sub-denumirea-de-educatie-sexuala-sustintuta-de-ministrul-educatiei-care-spune-ca-este-nevoie-si-de-educatie-parentala/)).\\n\\nPrin urmare, bazându-ne pe aceste surse, pare că stirea de pe site-ul menționat prezintă informații distorsionate și potențial înșelătoare despre poziția și intențiile USR în ceea ce privește educația sexuală în școli. Discursul promovat de site-ul respectiv pare să fie mai mult orientat spre propagandă decât spre o discuție obiectivă și informată despre subiect.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replace_unicode_chars(\"Site-ul postat pare s\\u0103 promoveze o perspectiv\\u0103 extrem de critic\\u0103 fa\\u021b\\u0103 de educa\\u021bia sexual\\u0103 \\u00een \\u0219coli, prezent\\u00e2nd-o \\u00eentr-o lumin\\u0103 negativ\\u0103 \\u0219i acuz\\u00e2nd USR de \\u00eendoctrinare cu \\\"propagand\\u0103 homosexual\\u0103\\\". Totu\\u0219i, informa\\u021biile disponibile din surse mai echilibrate \\u0219i de \\u00eencredere indic\\u0103 faptul c\\u0103 USR PLUS sus\\u021bine introducerea orelor de educa\\u021bie sexual\\u0103 \\u00een \\u0219coli ca un mijloc de a oferi tinerilor informa\\u021bii corecte \\u0219i s\\u0103n\\u0103toase despre sexualitate, s\\u0103n\\u0103tatea reproducerii \\u0219i rela\\u021bii. Conform unui articol de pe [Europa Liber\\u0103](https://romania.europalibera.org/a/educatie-sexuala-in-scoli/31315070.html), liderul USR PLUS, Dan Barna, a catalogat drept iresponsabili pe care se opun acestei educa\\u021bii.\\n\\n\\u00cen plus, cercet\\u0103rile indic\\u0103 un sprijin larg \\u00een r\\u00e2ndul popula\\u021biei pentru introducerea educa\\u021biei sexuale \\u00een \\u0219coli, cu un studiu ar\\u0103t\\u00e2nd c\\u0103 peste 83% din responden\\u021bi sus\\u021bin introducerea obligatorie a acestei materii ([EduPedu](https://www.edupedu.ro/cercetare-cu-privire-la-introducerea-educatiei-sexuale-in-scoli-peste-83-dintre-respondenti-sunt-pentru/)). De asemenea, Ministrul Educa\\u021biei, Sorin C\\u00eempeanu, a sus\\u021binut introducerea acestei educa\\u021bii ca disciplin\\u0103 obligatorie, subliniind necesitatea unei abord\\u0103ri inteligente \\u0219i adaptate realit\\u0103\\u021bilor comunit\\u0103\\u021bilor ([EduPedu](https://www.edupedu.ro/introducerea-educatiei-sexuale-in-scoli-ca-disciplina-obligatorie-sub-denumirea-de-educatie-sexuala-sustintuta-de-ministrul-educatiei-care-spune-ca-este-nevoie-si-de-educatie-parentala/)).\\n\\nPrin urmare, baz\\u00e2ndu-ne pe aceste surse, pare c\\u0103 stirea de pe site-ul men\\u021bionat prezint\\u0103 informa\\u021bii distorsionate \\u0219i poten\\u021bial \\u00een\\u0219el\\u0103toare despre pozi\\u021bia \\u0219i inten\\u021biile USR \\u00een ceea ce prive\\u0219te educa\\u021bia sexual\\u0103 \\u00een \\u0219coli. Discursul promovat de site-ul respectiv pare s\\u0103 fie mai mult orientat spre propagand\\u0103 dec\\u00e2t spre o discu\\u021bie obiectiv\\u0103 \\u0219i informat\\u0103 despre subiect.\"\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d068139-9395-486e-9988-0f2eb679bcad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dumitrescustefan/bert-base-romanian-cased-v1 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7867\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7867/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import functools, operator, requests, os, json\n",
    "from bs4 import BeautifulSoup\n",
    "from duckduckgo_search import DDGS\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain.tools import tool\n",
    "from typing import Annotated, Any, Dict, List, Optional, Sequence, TypedDict\n",
    "import gradio as gr\n",
    "import re\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('dumitrescustefan/bert-base-romanian-cased-v1')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('dumitrescustefan/bert-base-romanian-cased-v1')\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"LangGraph Research Agents\"\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4-turbo-preview\")\n",
    "\n",
    "def replace_unicode_chars(text):\n",
    "    replacements = {\n",
    "        '\\\\u0219': 'ș', '\\\\u0218': 'Ș',\n",
    "        '\\\\u021b': 'ț', '\\\\u021a': 'Ț',\n",
    "        '\\\\u0103': 'ă', '\\\\u0102': 'Ă',\n",
    "        '\\\\u00ee': 'î', '\\\\u00ce': 'Î',\n",
    "        '\\\\u00e2': 'â', '\\\\u00c2': 'Â',\n",
    "        '\\\\u00e3': 'ã', '\\\\u00c3': 'Ã',\n",
    "        '\\\\u00e0': 'à', '\\\\u00c0': 'À',\n",
    "        '\\\\u00e9': 'é', '\\\\u00c9': 'É',\n",
    "        '\\\\\\\"': '\"'\n",
    "    }\n",
    "    \n",
    "    for unicode_char, romanian_char in replacements.items():\n",
    "        text = text.replace(unicode_char, romanian_char)\n",
    "    \n",
    "    return text\n",
    "\n",
    "@tool(\"verify_content\", return_direct=False)\n",
    "def detect_fake_news(text: str) -> str:\n",
    "    \"\"\"Uses a pretrained Romanian model to predict whether the text is likely to be fake news.\"\"\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        predictions = torch.sigmoid(outputs.logits)\n",
    "        fake_news_prob = predictions[:, 1].item()\n",
    "\n",
    "    if fake_news_prob > 0.5:\n",
    "        return f\"Posibil știri false (Incredere: {fake_news_prob:.2f})\"\n",
    "    else:\n",
    "        return \"Probabil de încredere\"\n",
    "\n",
    "@tool(\"internet_search\", return_direct=False)\n",
    "def internet_search(query: str) -> str:\n",
    "    \"\"\"Searches the internet using DuckDuckGo, focusing on Romanian sources.\"\"\"\n",
    "    with DDGS() as ddgs:\n",
    "        results = [r for r in ddgs.text(f\"{query} site:.ro\", max_results=5)]\n",
    "        return results if results else \"Niciun rezultat găsit.\"\n",
    "\n",
    "@tool(\"process_content\", return_direct=False)\n",
    "def process_content(url: str) -> str:\n",
    "    \"\"\"Processes content from a Romanian webpage.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    return soup.get_text()\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    next: str\n",
    "\n",
    "tools = [internet_search, process_content, detect_fake_news]\n",
    "\n",
    "def create_agent(llm, tools, system_prompt):\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ])\n",
    "    agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "    executor = AgentExecutor(agent=agent, tools=tools)\n",
    "    return executor\n",
    "\n",
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    return {\"messages\": [HumanMessage(content=result[\"output\"], name=name)]}\n",
    "\n",
    "members = [\"Web_Searcher\", \"Insight_Researcher\"]\n",
    "system_prompt = (\n",
    "    \"As a supervisor, your role is to oversee a dialogue between these workers: {members}. \"\n",
    "    \"Based on the user's request, determine which worker should take the next action. \"\n",
    "    \"Each worker is responsible for executing a specific task and reporting back their findings and progress. \"\n",
    "    \"Once all tasks are complete, indicate with 'FINISH'.\"\n",
    ")\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "search_agent = create_agent(llm, tools, \"You are a web searcher. Search the internet for information.\")\n",
    "search_node = functools.partial(agent_node, agent=search_agent, name=\"Web_Searcher\")\n",
    "insights_research_agent = create_agent(llm, tools, \"\"\"You are a Insight Researcher. Do step by step. \n",
    "        Based on the provided content first verify the authenticity of information,\n",
    "        then search internet for other news related to the one it was provided\n",
    "        and finally find insights so you can say if the original news is fake or not.\n",
    "        Include the insights and sources in the final response\n",
    "        \"\"\")\n",
    "\n",
    "insights_research_node = functools.partial(agent_node, agent=insights_research_agent, name=\"Insight_Researcher\")\n",
    "\n",
    "workflow.add_node(\"Web_Searcher\", search_node)\n",
    "workflow.add_node(\"Insight_Researcher\", insights_research_node)\n",
    "\n",
    "for member in members:\n",
    "    workflow.add_edge(member, \"supervisor\")\n",
    "\n",
    "conditional_map = {k: k for k in members}\n",
    "conditional_map[\"FINISH\"] = END\n",
    "workflow.add_conditional_edges(\"supervisor\", lambda x: x[\"next\"], conditional_map)\n",
    "workflow.set_entry_point(\"supervisor\")\n",
    "\n",
    "def run_graph(input_message):\n",
    "    response = graph.invoke({\n",
    "        \"messages\": [HumanMessage(content=input_message)]\n",
    "    })\n",
    "    return json.dumps(replace_unicode_chars(response['messages'][1].content), indent=2)\n",
    "\n",
    "inputs = gr.Textbox(lines=2, placeholder=\"Enter your query here...\")\n",
    "outputs = gr.Textbox()\n",
    "\n",
    "demo = gr.Interface(fn=run_graph, inputs=inputs, outputs=outputs)\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd354f7-44c0-41ee-ac41-67cb3a936927",
   "metadata": {},
   "source": [
    "### Intrebarea: Verifica daca este falsa stirea de pe site-ul acesta: https://www.nationalisti.ro/el-este-masonul-crescut-la-san-de-servicii-pe-cale-sa-l-ingroape-pe-coldea/\n",
    "\n",
    "### Raspunsul: 'Informațiile pe care le-am găsit indică faptul că există o acoperire mediatică semnificativă despre Cătălin Hideg și Florian Coldea, ceea ce sugerează că știrea despre denunțul făcut de Cătălin Hideg împotriva lui Florian Coldea și altora este reală și nu pare a fi o știre falsă. Conform surselor, Florian Coldea, Dumitru Dumbravă și Doru Trăilă au fost plasați sub control judiciar după o plângere depusă de omul de afaceri Cătălin Hideg, care i-a denunțat la DNA pentru o cerere de mită în legătură cu un dosar de corupție. Aceste informații sunt raportate de surse credibile precum [Libertatea](https://www.libertatea.ro/stiri/prima-comunicare-oficiala-a-dna-despre-dosarul-in-care-florian-coldea-si-dumitru-dumbrava-au-fost-turnati-de-catalin-hideg-4900260) și [ProTV](https://stirileprotv.ro/stiri/actualitate/florian-coldea-fostul-sef-operativ-al-sri-generalul-dumbrava-si-un-avocat-au-fost-plasati-sub-control-judiciar.html).\\n\\nÎn contextul informațiilor disponibile, nu există indicii care să sugereze că știrea despre implicarea lui Cătălin Hideg în denunțarea unor persoane influente, cum ar fi Florian Coldea, este falsă. Cu toate acestea, este important să se ia în considerare că detaliile pot evolua pe măsură ce ancheta avansează și că informațiile ar trebui verificate pentru actualizări periodice.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d67dad68-0a9c-4b5c-95ff-64e59145ba1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Informațiile pe care le-am găsit indică faptul că există o acoperire mediatică semnificativă despre Cătălin Hideg și Florian Coldea, ceea ce sugerează că știrea despre denunțul făcut de Cătălin Hideg împotriva lui Florian Coldea și altora este reală și nu pare a fi o știre falsă. Conform surselor, Florian Coldea, Dumitru Dumbravă și Doru Trăilă au fost plasați sub control judiciar după o plângere depusă de omul de afaceri Cătălin Hideg, care i-a denunțat la DNA pentru o cerere de mită în legătură cu un dosar de corupție. Aceste informații sunt raportate de surse credibile precum [Libertatea](https://www.libertatea.ro/stiri/prima-comunicare-oficiala-a-dna-despre-dosarul-in-care-florian-coldea-si-dumitru-dumbrava-au-fost-turnati-de-catalin-hideg-4900260) și [ProTV](https://stirileprotv.ro/stiri/actualitate/florian-coldea-fostul-sef-operativ-al-sri-generalul-dumbrava-si-un-avocat-au-fost-plasati-sub-control-judiciar.html).\\n\\nÎn contextul informațiilor disponibile, nu există indicii care să sugereze că știrea despre implicarea lui Cătălin Hideg în denunțarea unor persoane influente, cum ar fi Florian Coldea, este falsă. Cu toate acestea, este important să se ia în considerare că detaliile pot evolua pe măsură ce ancheta avansează și că informațiile ar trebui verificate pentru actualizări periodice.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replace_unicode_chars(\"Informa\\u021biile pe care le-am g\\u0103sit indic\\u0103 faptul c\\u0103 exist\\u0103 o acoperire mediatic\\u0103 semnificativ\\u0103 despre C\\u0103t\\u0103lin Hideg \\u0219i Florian Coldea, ceea ce sugereaz\\u0103 c\\u0103 \\u0219tirea despre denun\\u021bul f\\u0103cut de C\\u0103t\\u0103lin Hideg \\u00eempotriva lui Florian Coldea \\u0219i altora este real\\u0103 \\u0219i nu pare a fi o \\u0219tire fals\\u0103. Conform surselor, Florian Coldea, Dumitru Dumbrav\\u0103 \\u0219i Doru Tr\\u0103il\\u0103 au fost plasa\\u021bi sub control judiciar dup\\u0103 o pl\\u00e2ngere depus\\u0103 de omul de afaceri C\\u0103t\\u0103lin Hideg, care i-a denun\\u021bat la DNA pentru o cerere de mit\\u0103 \\u00een leg\\u0103tur\\u0103 cu un dosar de corup\\u021bie. Aceste informa\\u021bii sunt raportate de surse credibile precum [Libertatea](https://www.libertatea.ro/stiri/prima-comunicare-oficiala-a-dna-despre-dosarul-in-care-florian-coldea-si-dumitru-dumbrava-au-fost-turnati-de-catalin-hideg-4900260) \\u0219i [ProTV](https://stirileprotv.ro/stiri/actualitate/florian-coldea-fostul-sef-operativ-al-sri-generalul-dumbrava-si-un-avocat-au-fost-plasati-sub-control-judiciar.html).\\n\\n\\u00cen contextul informa\\u021biilor disponibile, nu exist\\u0103 indicii care s\\u0103 sugereze c\\u0103 \\u0219tirea despre implicarea lui C\\u0103t\\u0103lin Hideg \\u00een denun\\u021barea unor persoane influente, cum ar fi Florian Coldea, este fals\\u0103. Cu toate acestea, este important s\\u0103 se ia \\u00een considerare c\\u0103 detaliile pot evolua pe m\\u0103sur\\u0103 ce ancheta avanseaz\\u0103 \\u0219i c\\u0103 informa\\u021biile ar trebui verificate pentru actualiz\\u0103ri periodice.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "303bc702-c3a4-4156-8478-e5dcd3096a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7873\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7873/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import functools, operator, requests, os, json\n",
    "from bs4 import BeautifulSoup\n",
    "from duckduckgo_search import DDGS\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain.tools import tool\n",
    "from typing import Annotated, Any, Dict, List, Optional, Sequence, TypedDict\n",
    "import gradio as gr\n",
    "import re\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"hamzab/roberta-fake-news-classification\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"hamzab/roberta-fake-news-classification\")\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"LangGraph Research Agents\"\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4-turbo-preview\")\n",
    "\n",
    "def replace_unicode_chars(text):\n",
    "    replacements = {\n",
    "        '\\\\u0219': 'ș', '\\\\u0218': 'Ș',\n",
    "        '\\\\u021b': 'ț', '\\\\u021a': 'Ț',\n",
    "        '\\\\u0103': 'ă', '\\\\u0102': 'Ă',\n",
    "        '\\\\u00ee': 'î', '\\\\u00ce': 'Î',\n",
    "        '\\\\u00e2': 'â', '\\\\u00c2': 'Â',\n",
    "        '\\\\u00e3': 'ã', '\\\\u00c3': 'Ã',\n",
    "        '\\\\u00e0': 'à', '\\\\u00c0': 'À',\n",
    "        '\\\\u00e9': 'é', '\\\\u00c9': 'É',\n",
    "        '\\\\\\\"': '\"'\n",
    "    }\n",
    "    \n",
    "    for unicode_char, romanian_char in replacements.items():\n",
    "        text = text.replace(unicode_char, romanian_char)\n",
    "    \n",
    "    return text\n",
    "\n",
    "@tool(\"verify_content\", return_direct=False)\n",
    "def detect_fake_news(title: str, text: str) -> str:\n",
    "    \"\"\"\n",
    "    Detects fake news based on the title and content of an article. \n",
    "    The function constructs an input string from title and text, processes it through a tokenizer, \n",
    "    and uses a machine learning model to predict the likelihood of the article being fake news.\n",
    "\n",
    "    Parameters:\n",
    "    - title (str): The title of the news article.\n",
    "    - text (str): The full content of the news article.\n",
    "\n",
    "    Returns:\n",
    "    - str: A string indicating the likelihood of the article being fake news.\n",
    "    \"\"\"\n",
    "    input_str = \"<title>\" + title + \"<content>\" +  text + \"<end>\"\n",
    "    input_ids = tokenizer.encode_plus(input_str, max_length=512, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "    device =  'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids[\"input_ids\"].to(device), attention_mask=input_ids[\"attention_mask\"].to(device))\n",
    "    return dict(zip([\"Fake\",\"Real\"], [x.item() for x in list(torch.nn.Softmax()(output.logits)[0])] ))\n",
    "\n",
    "@tool(\"internet_search\", return_direct=False)\n",
    "def internet_search(query: str) -> str:\n",
    "    \"\"\"Searches the internet using DuckDuckGo, focusing on Romanian sources.\"\"\"\n",
    "    with DDGS() as ddgs:\n",
    "        results = [r for r in ddgs.text(f\"{query} site:.ro\", max_results=5)]\n",
    "        return results if results else \"Niciun rezultat găsit.\"\n",
    "\n",
    "@tool(\"process_content\", return_direct=False)\n",
    "def process_content(url: str) -> str:\n",
    "    \"\"\"Processes content from a Romanian webpage.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    return soup.get_text()\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    next: str\n",
    "\n",
    "tools = [internet_search, process_content, detect_fake_news]\n",
    "\n",
    "def create_agent(llm, tools, system_prompt):\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ])\n",
    "    agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "    executor = AgentExecutor(agent=agent, tools=tools)\n",
    "    return executor\n",
    "\n",
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    processed_output = replace_unicode_chars(result[\"output\"])\n",
    "    return {\"messages\": [HumanMessage(content=processed_output, name=name)]}\n",
    "    #return {\"messages\": [HumanMessage(content=result[\"output\"], name=name)]}\n",
    "\n",
    "members = [\"Web_Searcher\", \"Insight_Researcher\"]\n",
    "system_prompt = (\n",
    "    \"As a supervisor, your role is to oversee a dialogue between these workers: {members}. \"\n",
    "    \"Based on the user's request, determine which worker should take the next action. \"\n",
    "    \"Each worker is responsible for executing a specific task and reporting back their findings and progress. \"\n",
    "    \"Once all tasks are complete, indicate with 'FINISH'.\"\n",
    ")\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "search_agent = create_agent(llm, tools, \"You are a web searcher. Search the internet for information and summarize it in english.\")\n",
    "search_node = functools.partial(agent_node, agent=search_agent, name=\"Web_Searcher\")\n",
    "insights_research_agent = create_agent(llm, tools, \"\"\"You are a Insight Researcher. Do step by step. \n",
    "        Based on the provided content first verify the authenticity of information and take into account the answer of the detect_fake_news tool,\n",
    "        then search internet for other news related to the one it was provided, provide links and quotes from reputable sources that relate to the original context of the news\n",
    "        and finally find insights so you can say if the original news is fake or not.\n",
    "        Include the insights and sources in the final response\n",
    "        \"\"\")\n",
    "\n",
    "insights_research_node = functools.partial(agent_node, agent=insights_research_agent, name=\"Insight_Researcher\")\n",
    "\n",
    "workflow.add_node(\"Web_Searcher\", search_node)\n",
    "workflow.add_node(\"Insight_Researcher\", insights_research_node)\n",
    "\n",
    "for member in members:\n",
    "    workflow.add_edge(member, \"supervisor\")\n",
    "\n",
    "conditional_map = {k: k for k in members}\n",
    "conditional_map[\"FINISH\"] = END\n",
    "workflow.add_conditional_edges(\"supervisor\", lambda x: x[\"next\"], conditional_map)\n",
    "workflow.set_entry_point(\"supervisor\")\n",
    "\n",
    "def run_graph(input_message):\n",
    "    response = graph.invoke({\n",
    "        \"messages\": [HumanMessage(content=input_message)]\n",
    "    })\n",
    "    processed_response = replace_unicode_chars(response['messages'][1].content)\n",
    "    return json.dumps(processed_response, indent=2)\n",
    "    \n",
    "\n",
    "inputs = gr.Textbox(lines=2, placeholder=\"Enter your query here...\")\n",
    "outputs = gr.Textbox()\n",
    "\n",
    "demo = gr.Interface(fn=run_graph, inputs=inputs, outputs=outputs)\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e9a38c-6f06-4ed2-aabd-9e7f325d9190",
   "metadata": {},
   "source": [
    "### Intrebarea: Verify if the following news is fake or not: https://www.nationalisti.ro/usr-militeaza-pentru-educatia-sexuala-in-scoli-ne-indoctrineaza-copiii-cu-propaganda-homosexuala/\n",
    "\n",
    "### Raspunsul: 'The claim presented in the article from nationalisti.ro that USR advocates for sexual education in schools as a means to indoctrinate children with \"homosexual propaganda\" is a contentious and highly politicized interpretation of the party\\'s stance on sexual education. The content of the article is heavily biased and seems to aim at discrediting USR\\'s support for sexual education by framing it in a negative light, particularly emphasizing a supposed agenda to promote homosexuality.\\n\\nIn contrast, according to information available from credible sources, USR PLUS (Uniunea Salvați România - Partidul Libertate, Unitate și Solidaritate) has indeed positioned itself in favor of introducing sexual education in schools. Dan Barna, a leader of USR PLUS, has labeled those opposing sexual education in schools as irresponsible. The intention behind the advocacy for sexual education by USR PLUS and other supporters is to address issues such as teenage pregnancy and to provide young people with knowledge on health and safety, including aspects related to sexual health.\\n\\nThis perspective is supported by a broader context in which sexual education is seen as a necessary component of modern education, aiming to inform and protect students rather than indoctrinate them with any particular ideology. The debate surrounding the introduction of sexual education in schools in Romania is part of a larger discourse on children\\'s rights, public health, and the role of education in addressing societal challenges.\\n\\nGiven the highly politicized nature of the discussion and the apparent bias in the original article, it\\'s important to approach the claim with caution and to consider the broader context and the intentions behind the push for sexual education in Romanian schools.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d5fa6c3a-3735-406b-86b3-2d943bcd4696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The claim presented in the article from nationalisti.ro that USR advocates for sexual education in schools as a means to indoctrinate children with \"homosexual propaganda\" is a contentious and highly politicized interpretation of the party\\'s stance on sexual education. The content of the article is heavily biased and seems to aim at discrediting USR\\'s support for sexual education by framing it in a negative light, particularly emphasizing a supposed agenda to promote homosexuality.\\n\\nIn contrast, according to information available from credible sources, USR PLUS (Uniunea Salvați România - Partidul Libertate, Unitate și Solidaritate) has indeed positioned itself in favor of introducing sexual education in schools. Dan Barna, a leader of USR PLUS, has labeled those opposing sexual education in schools as irresponsible. The intention behind the advocacy for sexual education by USR PLUS and other supporters is to address issues such as teenage pregnancy and to provide young people with knowledge on health and safety, including aspects related to sexual health.\\n\\nThis perspective is supported by a broader context in which sexual education is seen as a necessary component of modern education, aiming to inform and protect students rather than indoctrinate them with any particular ideology. The debate surrounding the introduction of sexual education in schools in Romania is part of a larger discourse on children\\'s rights, public health, and the role of education in addressing societal challenges.\\n\\nGiven the highly politicized nature of the discussion and the apparent bias in the original article, it\\'s important to approach the claim with caution and to consider the broader context and the intentions behind the push for sexual education in Romanian schools.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replace_unicode_chars(\"The claim presented in the article from nationalisti.ro that USR advocates for sexual education in schools as a means to indoctrinate children with \\\"homosexual propaganda\\\" is a contentious and highly politicized interpretation of the party's stance on sexual education. The content of the article is heavily biased and seems to aim at discrediting USR's support for sexual education by framing it in a negative light, particularly emphasizing a supposed agenda to promote homosexuality.\\n\\nIn contrast, according to information available from credible sources, USR PLUS (Uniunea Salva\\u021bi Rom\\u00e2nia - Partidul Libertate, Unitate \\u0219i Solidaritate) has indeed positioned itself in favor of introducing sexual education in schools. Dan Barna, a leader of USR PLUS, has labeled those opposing sexual education in schools as irresponsible. The intention behind the advocacy for sexual education by USR PLUS and other supporters is to address issues such as teenage pregnancy and to provide young people with knowledge on health and safety, including aspects related to sexual health.\\n\\nThis perspective is supported by a broader context in which sexual education is seen as a necessary component of modern education, aiming to inform and protect students rather than indoctrinate them with any particular ideology. The debate surrounding the introduction of sexual education in schools in Romania is part of a larger discourse on children's rights, public health, and the role of education in addressing societal challenges.\\n\\nGiven the highly politicized nature of the discussion and the apparent bias in the original article, it's important to approach the claim with caution and to consider the broader context and the intentions behind the push for sexual education in Romanian schools.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927c64e8-6197-4d87-83d0-7d3bf6422f1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a4d39057-ffb6-475b-ab3f-cf5869f14bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7874\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7874/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import functools, operator, requests, os, json\n",
    "from bs4 import BeautifulSoup\n",
    "from duckduckgo_search import DDGS\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain.tools import tool\n",
    "from typing import Annotated, Any, Dict, List, Optional, Sequence, TypedDict\n",
    "import gradio as gr\n",
    "import re\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"hamzab/roberta-fake-news-classification\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"hamzab/roberta-fake-news-classification\")\n",
    "\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"LangGraph Research Agents\"\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4-turbo-preview\")\n",
    "\n",
    "def replace_unicode_chars(text):\n",
    "    # Dicționar de înlocuiri\n",
    "    replacements = {\n",
    "        '\\\\u0219': 'ș', '\\\\u0218': 'Ș',\n",
    "        '\\\\u021b': 'ț', '\\\\u021a': 'Ț',\n",
    "        '\\\\u0103': 'ă', '\\\\u0102': 'Ă',\n",
    "        '\\\\u00ee': 'î', '\\\\u00ce': 'Î',\n",
    "        '\\\\u00e2': 'â', '\\\\u00c2': 'Â',\n",
    "        '\\\\u00e3': 'ã', '\\\\u00c3': 'Ã',\n",
    "        '\\\\u00e0': 'à', '\\\\u00c0': 'À',\n",
    "        '\\\\u00e9': 'é', '\\\\u00c9': 'É',\n",
    "        '\\\\\\\"': '\"'\n",
    "    }\n",
    "    \n",
    "    # Înlocuirea fiecărui cod unicode cu caracterul corespunzător\n",
    "    for unicode_char, romanian_char in replacements.items():\n",
    "        text = text.replace(unicode_char, romanian_char)\n",
    "    \n",
    "    return text\n",
    "\n",
    "@tool(\"verify_content\", return_direct=False)\n",
    "def detect_fake_news(title: str, text: str) -> str:\n",
    "    \"\"\"\n",
    "    Detects fake news based on the title and content of an article. \n",
    "    The function constructs an input string from title and text, processes it through a tokenizer, \n",
    "    and uses a machine learning model to predict the likelihood of the article being fake news.\n",
    "\n",
    "    Parameters:\n",
    "    - title (str): The title of the news article.\n",
    "    - text (str): The full content of the news article.\n",
    "\n",
    "    Returns:\n",
    "    - str: A string indicating the likelihood of the article being fake news.\n",
    "    \"\"\"\n",
    "    input_str = \"<title>\" + title + \"<content>\" +  text + \"<end>\"\n",
    "    input_ids = tokenizer.encode_plus(input_str, max_length=512, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "    device =  'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids[\"input_ids\"].to(device), attention_mask=input_ids[\"attention_mask\"].to(device))\n",
    "    return dict(zip([\"Fake\",\"Real\"], [x.item() for x in list(torch.nn.Softmax()(output.logits)[0])] ))\n",
    "\n",
    "@tool(\"internet_search\", return_direct=False)\n",
    "def internet_search(query: str) -> str:\n",
    "    \"\"\"Searches the internet using DuckDuckGo, focusing on Romanian sources.\"\"\"\n",
    "    with DDGS() as ddgs:\n",
    "        results = [r for r in ddgs.text(f\"{query} site:.ro\", max_results=5)]\n",
    "        return results if results else \"Niciun rezultat găsit.\"\n",
    "\n",
    "@tool(\"process_content\", return_direct=False)\n",
    "def process_content(url: str) -> str:\n",
    "    \"\"\"Processes content from a Romanian webpage.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    return soup.get_text()\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    next: str\n",
    "\n",
    "tools = [internet_search, process_content, detect_fake_news]\n",
    "\n",
    "def create_agent(llm, tools, system_prompt):\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ])\n",
    "    agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "    executor = AgentExecutor(agent=agent, tools=tools)\n",
    "    return executor\n",
    "\n",
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    processed_output = replace_unicode_chars(result[\"output\"])\n",
    "    return {\"messages\": [HumanMessage(content=processed_output, name=name)]}\n",
    "    #return {\"messages\": [HumanMessage(content=result[\"output\"], name=name)]}\n",
    "\n",
    "members = [\"Web_Searcher\", \"Insight_Researcher\"]\n",
    "system_prompt = (\n",
    "    \"As a supervisor, your role is to oversee a dialogue between these workers: {members}. \"\n",
    "    \"Based on the user's request, determine which worker should take the next action. \"\n",
    "    \"Each worker is responsible for executing a specific task and reporting back their findings and progress. \"\n",
    "    \"Once all tasks are complete, indicate with 'FINISH'.\"\n",
    ")\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "search_agent = create_agent(llm, tools, \"You are a web searcher. Search the internet for information and summarize it in english.\")\n",
    "search_node = functools.partial(agent_node, agent=search_agent, name=\"Web_Searcher\")\n",
    "insights_research_agent = create_agent(llm, tools, \"\"\"You are a Insight Researcher. Do step by step. \n",
    "        Based on the provided content first verify the authenticity of information and take into account the answer of the detect_fake_news tool,\n",
    "        then search internet for other news related to the one it was provided, provide links and quotes from reputable sources that relate to the original context of the news\n",
    "        and finally find insights so you can say if the original news is fake or not.\n",
    "        Include the insights and sources in the final response\n",
    "        \"\"\")\n",
    "\n",
    "insights_research_node = functools.partial(agent_node, agent=insights_research_agent, name=\"Insight_Researcher\")\n",
    "\n",
    "workflow.add_node(\"Web_Searcher\", search_node)\n",
    "workflow.add_node(\"Insight_Researcher\", insights_research_node)\n",
    "\n",
    "for member in members:\n",
    "    workflow.add_edge(member, \"supervisor\")\n",
    "\n",
    "conditional_map = {k: k for k in members}\n",
    "conditional_map[\"FINISH\"] = END\n",
    "workflow.add_conditional_edges(\"supervisor\", lambda x: x[\"next\"], conditional_map)\n",
    "workflow.set_entry_point(\"supervisor\")\n",
    "\n",
    "def run_graph(input_message):\n",
    "    response = graph.invoke({\n",
    "        \"messages\": [HumanMessage(content=input_message)]\n",
    "    })\n",
    "    processed_response = replace_unicode_chars(response['messages'][1].content)\n",
    "    return json.dumps(processed_response, indent=2)\n",
    "    \n",
    "\n",
    "inputs = gr.Textbox(lines=2, placeholder=\"Enter your query here...\")\n",
    "outputs = gr.Textbox()\n",
    "\n",
    "demo = gr.Interface(fn=run_graph, inputs=inputs, outputs=outputs)\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b560929f-1233-475d-849b-6319b153007c",
   "metadata": {},
   "source": [
    "### Intrebarea: Verify if the following news is fake or not:https://www.nationalisti.ro/profesorul-ion-coja-rasa-alba-este-in-cel-mai-mare-pericol/\n",
    "\n",
    "### Raspunsul:\n",
    "\"The content from the provided URL contains highly controversial statements and views attributed to Ion Coja, including claims about racial superiority, anti-Semitic conspiracies, and other extreme views. The source \\\"nationalisti.ro\\\" and the nature of the content suggest that it may not align with mainstream journalistic standards or academic research.\\n\\nTo verify the authenticity and evaluate the legitimacy of the content, it's important to consider the credibility of the source. \\\"Nationalisti.ro\\\" appears to be a platform that may promote nationalist or extreme viewpoints, which could indicate a bias or agenda in the information it publishes.\\n\\nFor a thorough analysis, it's advisable to cross-reference the claims made in the article with reputable news sources, academic research, or reports from established human rights organizations. This can help determine the accuracy of the information and the context in which the statements were made.\\n\\nGiven the controversial nature of the content and the potential for it to spread misinformation or harmful ideologies, it's crucial to approach such information critically and seek out balanced and reliable sources for verification.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c01a1a8d-29ab-4031-a3bd-3cc624e274a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Materialul prezentat pe site-ul nationalisti.ro, sub titlul \"Profesorul Ion Coja: \\'Rasa albă este în cel mai mare pericol!\\'\", este un text care conține afirmații și idei extrem de controversate și, în multe cazuri, deschis rasiste și antisemite. Textul atribuit lui Ion Coja promovează teorii ale conspirației, discriminare rasială și religioasă, și viziuni anti-semite, care pot fi considerate nu doar ofensatoare, dar și periculoase prin incitarea la ură și discriminare.\\n\\nEste important să se facă distincția între libertatea de exprimare și promovarea discursului de ură sau a teoriilor conspirative nedovedite care pot alimenta discriminarea și violența. Materiale de acest tip, care propun o viziune distorsionată asupra istoriei și promovează segregarea pe criterii rasiale sau religioase, sunt adesea respinse de comunitatea academică și de societatea civilă pentru lipsa lor de fundament științific și tendința de a diviza societatea.\\n\\nPentru a verifica dacă informațiile prezentate în acest articol sunt false sau înșelătoare, ar fi necesară o analiză mai detaliată, inclusiv consultarea de surse istorice și științifice credibile, precum și a opiniilor experților în istorie, sociologie și studii despre discriminare și rasism. Totodată, este util să se consulte organizații și instituții recunoscute pentru lupta împotriva discriminării și promovarea drepturilor omului, care pot oferi o perspectivă echilibrată și informată despre astfel de subiecte.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replace_unicode_chars(\"Materialul prezentat pe site-ul nationalisti.ro, sub titlul \\\"Profesorul Ion Coja: 'Rasa alb\\u0103 este \\u00een cel mai mare pericol!'\\\", este un text care con\\u021bine afirma\\u021bii \\u0219i idei extrem de controversate \\u0219i, \\u00een multe cazuri, deschis rasiste \\u0219i antisemite. Textul atribuit lui Ion Coja promoveaz\\u0103 teorii ale conspira\\u021biei, discriminare rasial\\u0103 \\u0219i religioas\\u0103, \\u0219i viziuni anti-semite, care pot fi considerate nu doar ofensatoare, dar \\u0219i periculoase prin incitarea la ur\\u0103 \\u0219i discriminare.\\n\\nEste important s\\u0103 se fac\\u0103 distinc\\u021bia \\u00eentre libertatea de exprimare \\u0219i promovarea discursului de ur\\u0103 sau a teoriilor conspirative nedovedite care pot alimenta discriminarea \\u0219i violen\\u021ba. Materiale de acest tip, care propun o viziune distorsionat\\u0103 asupra istoriei \\u0219i promoveaz\\u0103 segregarea pe criterii rasiale sau religioase, sunt adesea respinse de comunitatea academic\\u0103 \\u0219i de societatea civil\\u0103 pentru lipsa lor de fundament \\u0219tiin\\u021bific \\u0219i tendin\\u021ba de a diviza societatea.\\n\\nPentru a verifica dac\\u0103 informa\\u021biile prezentate \\u00een acest articol sunt false sau \\u00een\\u0219el\\u0103toare, ar fi necesar\\u0103 o analiz\\u0103 mai detaliat\\u0103, inclusiv consultarea de surse istorice \\u0219i \\u0219tiin\\u021bifice credibile, precum \\u0219i a opiniilor exper\\u021bilor \\u00een istorie, sociologie \\u0219i studii despre discriminare \\u0219i rasism. Totodat\\u0103, este util s\\u0103 se consulte organiza\\u021bii \\u0219i institu\\u021bii recunoscute pentru lupta \\u00eempotriva discrimin\\u0103rii \\u0219i promovarea drepturilor omului, care pot oferi o perspectiv\\u0103 echilibrat\\u0103 \\u0219i informat\\u0103 despre astfel de subiecte.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "943ded7b-90ed-48b2-be91-dd2c86973b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7878\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7878/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/kossee/anaconda3/lib/python3.10/site-packages/gradio/queueing.py\", line 528, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"/Users/kossee/anaconda3/lib/python3.10/site-packages/gradio/route_utils.py\", line 270, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/Users/kossee/anaconda3/lib/python3.10/site-packages/gradio/blocks.py\", line 1908, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/Users/kossee/anaconda3/lib/python3.10/site-packages/gradio/blocks.py\", line 1485, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"/Users/kossee/anaconda3/lib/python3.10/site-packages/anyio/to_thread.py\", line 28, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(func, *args, cancellable=cancellable,\n",
      "  File \"/Users/kossee/anaconda3/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 818, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/Users/kossee/anaconda3/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 754, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/Users/kossee/anaconda3/lib/python3.10/site-packages/gradio/utils.py\", line 808, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"/var/folders/n0/4tf_05553t78bflg03rdb89h0000gn/T/ipykernel_56787/604280744.py\", line 142, in run_graph\n",
      "    response = graph.invoke({\n",
      "  File \"/Users/kossee/anaconda3/lib/python3.10/site-packages/langgraph/pregel/__init__.py\", line 1333, in invoke\n",
      "    for chunk in self.stream(\n",
      "  File \"/Users/kossee/anaconda3/lib/python3.10/site-packages/langgraph/pregel/__init__.py\", line 876, in stream\n",
      "    _panic_or_proceed(done, inflight, step)\n",
      "  File \"/Users/kossee/anaconda3/lib/python3.10/site-packages/langgraph/pregel/__init__.py\", line 1422, in _panic_or_proceed\n",
      "    raise exc\n",
      "  File \"/Users/kossee/anaconda3/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/Users/kossee/anaconda3/lib/python3.10/site-packages/langgraph/pregel/retry.py\", line 66, in run_with_retry\n",
      "    task.proc.invoke(task.input, task.config)\n",
      "  File \"/Users/kossee/anaconda3/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 2368, in invoke\n",
      "    input = step.invoke(\n",
      "  File \"/Users/kossee/anaconda3/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 4396, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"/Users/kossee/anaconda3/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 170, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"/Users/kossee/anaconda3/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 599, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"/Users/kossee/anaconda3/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 456, in generate\n",
      "    raise e\n",
      "  File \"/Users/kossee/anaconda3/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 446, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"/Users/kossee/anaconda3/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 671, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"/Users/kossee/anaconda3/lib/python3.10/site-packages/langchain_openai/chat_models/base.py\", line 522, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "  File \"/Users/kossee/anaconda3/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/kossee/anaconda3/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 590, in create\n",
      "    return self._post(\n",
      "  File \"/Users/kossee/anaconda3/lib/python3.10/site-packages/openai/_base_client.py\", line 1240, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/kossee/anaconda3/lib/python3.10/site-packages/openai/_base_client.py\", line 921, in request\n",
      "    return self._request(\n",
      "  File \"/Users/kossee/anaconda3/lib/python3.10/site-packages/openai/_base_client.py\", line 1005, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/kossee/anaconda3/lib/python3.10/site-packages/openai/_base_client.py\", line 1053, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/kossee/anaconda3/lib/python3.10/site-packages/openai/_base_client.py\", line 1005, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/kossee/anaconda3/lib/python3.10/site-packages/openai/_base_client.py\", line 1053, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/kossee/anaconda3/lib/python3.10/site-packages/openai/_base_client.py\", line 1020, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    }
   ],
   "source": [
    "import functools, operator, requests, os, json\n",
    "from bs4 import BeautifulSoup\n",
    "from duckduckgo_search import DDGS\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain.tools import tool\n",
    "from typing import Annotated, Any, Dict, List, Optional, Sequence, TypedDict\n",
    "import gradio as gr\n",
    "import re\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"hamzab/roberta-fake-news-classification\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"hamzab/roberta-fake-news-classification\")\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"LangGraph Research Agents\"\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4-turbo-preview\")\n",
    "\n",
    "def replace_unicode_chars(text):\n",
    "    replacements = {\n",
    "        '\\\\u0219': 'ș', '\\\\u0218': 'Ș',\n",
    "        '\\\\u021b': 'ț', '\\\\u021a': 'Ț',\n",
    "        '\\\\u0103': 'ă', '\\\\u0102': 'Ă',\n",
    "        '\\\\u00ee': 'î', '\\\\u00ce': 'Î',\n",
    "        '\\\\u00e2': 'â', '\\\\u00c2': 'Â',\n",
    "        '\\\\u00e3': 'ã', '\\\\u00c3': 'Ã',\n",
    "        '\\\\u00e0': 'à', '\\\\u00c0': 'À',\n",
    "        '\\\\u00e9': 'é', '\\\\u00c9': 'É',\n",
    "        '\\\\\\\"': '\"'\n",
    "    }\n",
    "    \n",
    "    for unicode_char, romanian_char in replacements.items():\n",
    "        text = text.replace(unicode_char, romanian_char)\n",
    "    \n",
    "    return text\n",
    "\n",
    "@tool(\"verify_content\", return_direct=False)\n",
    "def detect_fake_news(title: str, text: str) -> str:\n",
    "    \"\"\"\n",
    "    Detects fake news based on the title and content of an article. \n",
    "    The function constructs an input string from title and text, processes it through a tokenizer, \n",
    "    and uses a machine learning model to predict the likelihood of the article being fake news.\n",
    "\n",
    "    Parameters:\n",
    "    - title (str): The title of the news article.\n",
    "    - text (str): The full content of the news article.\n",
    "\n",
    "    Returns:\n",
    "    - str: A string indicating the likelihood of the article being fake news.\n",
    "    \"\"\"\n",
    "    input_str = \"<title>\" + title + \"<content>\" +  text + \"<end>\"\n",
    "    input_ids = tokenizer.encode_plus(input_str, max_length=512, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "    device =  'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids[\"input_ids\"].to(device), attention_mask=input_ids[\"attention_mask\"].to(device))\n",
    "    return dict(zip([\"Fake\",\"Real\"], [x.item() for x in list(torch.nn.Softmax()(output.logits)[0])] ))\n",
    "\n",
    "@tool(\"internet_search\", return_direct=False)\n",
    "def internet_search(query: str) -> str:\n",
    "    \"\"\"Searches the internet using DuckDuckGo, focusing on Romanian sources.\"\"\"\n",
    "    with DDGS() as ddgs:\n",
    "        results = [r for r in ddgs.text(f\"{query} site:.ro\", max_results=5)]\n",
    "        return results if results else \"Niciun rezultat găsit.\"\n",
    "\n",
    "@tool(\"process_content\", return_direct=False)\n",
    "def process_content(url: str) -> str:\n",
    "    \"\"\"Processes content from a Romanian webpage.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    return soup.get_text()\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    next: str\n",
    "\n",
    "tools = [internet_search, process_content, detect_fake_news]\n",
    "\n",
    "def create_agent(llm, tools, system_prompt):\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ])\n",
    "    agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "    executor = AgentExecutor(agent=agent, tools=tools)\n",
    "    return executor\n",
    "\n",
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    processed_output = replace_unicode_chars(result[\"output\"])\n",
    "    return {\"messages\": [HumanMessage(content=processed_output, name=name)]}\n",
    "    #return {\"messages\": [HumanMessage(content=result[\"output\"], name=name)]}\n",
    "\n",
    "members = [\"Web_Searcher\", \"Insight_Researcher\"]\n",
    "system_prompt = (\n",
    "    \"As a supervisor, your role is to oversee a dialogue between these workers: {members}. \"\n",
    "    \"Based on the user's request, determine which worker should take the next action. \"\n",
    "    \"Each worker is responsible for executing a specific task and reporting back their findings and progress. \"\n",
    "    \"Once all tasks are complete, indicate with 'FINISH'.\"\n",
    ")\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "search_agent = create_agent(llm, tools, \"You are a web searcher. Search the internet for information and summarize it in english.\")\n",
    "search_node = functools.partial(agent_node, agent=search_agent, name=\"Web_Searcher\")\n",
    "insights_research_agent = create_agent(llm, tools, \"\"\"You are a Insight Researcher. Do step by step. \n",
    "        Based on the provided content first verify the authenticity of information and take into account the answer of the detect_fake_news tool,\n",
    "        then for a comprehensive assessment of the article's claims and to verify if the news is fake or not, cross-reference the events described with reports from established news organizations known for their journalistic standards\n",
    "        and finally find insights so you can say if the original news is fake or not.\n",
    "        search for more information on this topic from other sources to provide a balanced view.\n",
    "        Include the insights and sources with quotes in the final response.\n",
    "        \"\"\")\n",
    "\n",
    "insights_research_node = functools.partial(agent_node, agent=insights_research_agent, name=\"Insight_Researcher\")\n",
    "\n",
    "workflow.add_node(\"Web_Searcher\", search_node)\n",
    "workflow.add_node(\"Insight_Researcher\", insights_research_node)\n",
    "\n",
    "for member in members:\n",
    "    workflow.add_edge(member, \"supervisor\")\n",
    "\n",
    "conditional_map = {k: k for k in members}\n",
    "conditional_map[\"FINISH\"] = END\n",
    "workflow.add_conditional_edges(\"supervisor\", lambda x: x[\"next\"], conditional_map)\n",
    "workflow.set_entry_point(\"supervisor\")\n",
    "\n",
    "def run_graph(input_message):\n",
    "    response = graph.invoke({\n",
    "        \"messages\": [HumanMessage(content=input_message)]\n",
    "    })\n",
    "    processed_response = replace_unicode_chars(response['messages'][1].content)\n",
    "    return json.dumps(processed_response, indent=2)\n",
    "    \n",
    "\n",
    "inputs = gr.Textbox(lines=2, placeholder=\"Enter your query here...\")\n",
    "outputs = gr.Textbox()\n",
    "\n",
    "demo = gr.Interface(fn=run_graph, inputs=inputs, outputs=outputs)\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7478f6-28be-43b2-875d-d9ce837538dd",
   "metadata": {},
   "source": [
    "### Intrebarea: Verify if the following news is fake or not:https://www.nationalisti.ro/masacrul-de-la-festival-alt-exemplu-de-propaganda-de-atrocitate/\n",
    "\n",
    "### Raspunsul:\n",
    "\"The information provided in the article from nationalisti.ro discusses an event referred to as \\\"Masacrul de la Festival\\\" and presents a narrative that challenges the mainstream reporting of a massacre at a music festival, where it is claimed that \\\"260 girls were not targeted, raped, or killed by Hamas\\\" and that the Israeli Defense Forces (IDF) attacked Hamas militants near the festival site, leading to a scenario where festivalgoers fled the scene. The article suggests that the narrative of a massacre involving 250 innocent civilians being slaughtered is a form of atrocity propaganda utilized to justify ongoing violence in Gaza. It also mentions that the content and event sequence are based on a New York Times article, encouraging readers to watch a video and read the NYT article to form their own opinion on the incident.\\n\\nGiven the nature of the claims and the source's own positioning as politically incorrect, and without mainstream verification of the events described or the narratives proposed, it's important to approach the information with caution. The site seems to have a specific agenda, and the language used in the article is indicative of a bias towards a particular narrative about the Israeli-Palestinian conflict. This bias and the lack of external verification from more widely recognized news sources make it challenging to assess the veracity of the claims made without further information or context from reliable and impartial news outlets.\\n\\nFor a comprehensive assessment of the article's claims and to verify if the news is fake or not, it would be necessary to cross-reference the events described with reports from established news organizations known for their journalistic standards and to consider the broader context of the Israeli-Palestinian conflict, including the sources and motivations behind different narratives.\"\n",
    "\n",
    "### alta intrebare pe subiect: Verify if the following news is fake or not: https://www.nationalisti.ro/colonel-vasile-zarnescu-sintagma-razboiul-israel-hamas-o-dezinformare-crasa-si-un-gheseft-super-abject/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b3e791-dc92-471e-9c0b-8c6900af1dcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca627f8-e175-46a5-ae8a-5ca49e2261b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed05b3d-8adf-4bf5-a9cc-48aaa58e2150",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8840cdcc-fbc0-49cc-9cf0-80e6de0ae70a",
   "metadata": {},
   "source": [
    "# Incercam model free llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f00c4a41-fdd6-4a64-8eb6-1a4ff1130d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.2.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from langchain_community) (6.0.1)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.0 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from langchain_community) (0.2.0)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from langchain_community) (1.26.0)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from langchain_community) (0.1.59)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from langchain_community) (0.6.6)\n",
      "Requirement already satisfied: langchain<0.3.0,>=0.2.0 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from langchain_community) (0.2.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from langchain_community) (8.3.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from langchain_community) (2.0.30)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from langchain_community) (3.9.1)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from langchain_community) (2.31.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from langchain<0.3.0,>=0.2.0->langchain_community) (2.5.1)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from langchain<0.3.0,>=0.2.0->langchain_community) (0.2.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.0->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.0->langchain_community) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (2023.11.17)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (4.8.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain_community) (2.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain_community) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.3 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain_community) (2.14.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Installing collected packages: langchain_community\n",
      "Successfully installed langchain_community-0.2.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5f661065-0108-43a5-a7fd-1a84944d65c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet  text-generation transformers google-search-results numexpr langchainhub sentencepiece jinja2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fc58fdc-a8c3-4887-9ff6-597497923139",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kossee/anaconda3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "#os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \n",
    "\n",
    "from langchain_community.llms import HuggingFaceHub\n",
    "\n",
    "llm = HuggingFaceHub(\n",
    "    repo_id=\"HuggingFaceH4/zephyr-7b-beta\",\n",
    "    task=\"text-generation\",\n",
    "    model_kwargs={\n",
    "        \"max_new_tokens\": 512,\n",
    "        \"top_k\": 30,\n",
    "        \"temperature\": 0.1,\n",
    "        \"repetition_penalty\": 1.03,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e56411e-d4ed-4c64-b55f-5e2d4412d646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /Users/kossee/anaconda3/lib/python3.10/site-packages (0.23.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from huggingface_hub) (4.8.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from huggingface_hub) (6.0.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from huggingface_hub) (2023.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from huggingface_hub) (23.2)\n",
      "Requirement already satisfied: requests in /Users/kossee/anaconda3/lib/python3.10/site-packages (from huggingface_hub) (2.31.0)\n",
      "Requirement already satisfied: filelock in /Users/kossee/anaconda3/lib/python3.10/site-packages (from huggingface_hub) (3.12.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from huggingface_hub) (4.65.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from requests->huggingface_hub) (2023.11.17)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from requests->huggingface_hub) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from requests->huggingface_hub) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/kossee/anaconda3/lib/python3.10/site-packages (from requests->huggingface_hub) (2.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub\n",
    "#!python -c \"from huggingface_hub.hf_api import HfFolder; HfFolder.save_token('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')\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0c9a920-b75a-495a-bf30-8343164917e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models.huggingface import ChatHuggingFace\n",
    "from langchain_community.llms import HuggingFaceHub\n",
    "\n",
    "llm = HuggingFaceHub(\n",
    "    repo_id=\"HuggingFaceH4/zephyr-7b-beta\",\n",
    "    task=\"text-generation\",\n",
    "    model_kwargs={\n",
    "        \"max_new_tokens\": 512,\n",
    "        \"top_k\": 30,\n",
    "        \"temperature\": 0.1,\n",
    "        \"repetition_penalty\": 1.03,\n",
    "    },\n",
    ")\n",
    "\n",
    "chat_model = ChatHuggingFace(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1c4b9b7-711d-4ab5-9b0e-9b9f0a73753e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/kossee/anaconda3/lib/python3.10/site-packages/gradio/queueing.py\", line 528, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"/Users/kossee/anaconda3/lib/python3.10/site-packages/gradio/route_utils.py\", line 270, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/Users/kossee/anaconda3/lib/python3.10/site-packages/gradio/blocks.py\", line 1908, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/Users/kossee/anaconda3/lib/python3.10/site-packages/gradio/blocks.py\", line 1485, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"/Users/kossee/anaconda3/lib/python3.10/site-packages/anyio/to_thread.py\", line 28, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(func, *args, cancellable=cancellable,\n",
      "  File \"/Users/kossee/anaconda3/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 818, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/Users/kossee/anaconda3/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 754, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/Users/kossee/anaconda3/lib/python3.10/site-packages/gradio/utils.py\", line 808, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"/var/folders/n0/4tf_05553t78bflg03rdb89h0000gn/T/ipykernel_64315/1900643948.py\", line 144, in run_graph\n",
      "    response = workflow.invoke({\n",
      "AttributeError: 'StateGraph' object has no attribute 'invoke'\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kossee/anaconda3/lib/python3.10/site-packages/gradio/queueing.py\", line 528, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"/Users/kossee/anaconda3/lib/python3.10/site-packages/gradio/route_utils.py\", line 270, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/Users/kossee/anaconda3/lib/python3.10/site-packages/gradio/blocks.py\", line 1908, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/Users/kossee/anaconda3/lib/python3.10/site-packages/gradio/blocks.py\", line 1485, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"/Users/kossee/anaconda3/lib/python3.10/site-packages/anyio/to_thread.py\", line 28, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(func, *args, cancellable=cancellable,\n",
      "  File \"/Users/kossee/anaconda3/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 818, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/Users/kossee/anaconda3/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 754, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/Users/kossee/anaconda3/lib/python3.10/site-packages/gradio/utils.py\", line 808, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"/var/folders/n0/4tf_05553t78bflg03rdb89h0000gn/T/ipykernel_64315/1900643948.py\", line 144, in run_graph\n",
      "    response = workflow.invoke({\n",
      "AttributeError: 'StateGraph' object has no attribute 'invoke'\n"
     ]
    }
   ],
   "source": [
    "import functools, operator, requests, os, json\n",
    "from bs4 import BeautifulSoup\n",
    "from duckduckgo_search import DDGS\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain.tools import tool\n",
    "from typing import Annotated, Any, Dict, List, Optional, Sequence, TypedDict\n",
    "import gradio as gr\n",
    "import re\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "from langchain_community.chat_models.huggingface import ChatHuggingFace\n",
    "\n",
    "chat_model = ChatHuggingFace(llm=llm)\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"hamzab/roberta-fake-news-classification\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"hamzab/roberta-fake-news-classification\")\n",
    "\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"LangGraph Research Agents\"\n",
    "\n",
    "\n",
    "\n",
    "def replace_unicode_chars(text):\n",
    "    replacements = {\n",
    "        '\\\\u0219': 'ș', '\\\\u0218': 'Ș',\n",
    "        '\\\\u021b': 'ț', '\\\\u021a': 'Ț',\n",
    "        '\\\\u0103': 'ă', '\\\\u0102': 'Ă',\n",
    "        '\\\\u00ee': 'î', '\\\\u00ce': 'Î',\n",
    "        '\\\\u00e2': 'â', '\\\\u00c2': 'Â',\n",
    "        '\\\\u00e3': 'ã', '\\\\u00c3': 'Ã',\n",
    "        '\\\\u00e0': 'à', '\\\\u00c0': 'À',\n",
    "        '\\\\u00e9': 'é', '\\\\u00c9': 'É',\n",
    "        '\\\\\\\"': '\"'\n",
    "    }\n",
    "    \n",
    "    for unicode_char, romanian_char in replacements.items():\n",
    "        text = text.replace(unicode_char, romanian_char)\n",
    "    \n",
    "    return text\n",
    "\n",
    "@tool(\"verify_content\", return_direct=False)\n",
    "def detect_fake_news(title: str, text: str) -> str:\n",
    "    \"\"\"\n",
    "    Detects fake news based on the title and content of an article. \n",
    "    The function constructs an input string from title and text, processes it through a tokenizer, \n",
    "    and uses a machine learning model to predict the likelihood of the article being fake news.\n",
    "\n",
    "    Parameters:\n",
    "    - title (str): The title of the news article.\n",
    "    - text (str): The full content of the news article.\n",
    "\n",
    "    Returns:\n",
    "    - str: A string indicating the likelihood of the article being fake news.\n",
    "    \"\"\"\n",
    "    input_str = \"<title>\" + title + \"<content>\" +  text + \"<end>\"\n",
    "    input_ids = tokenizer.encode_plus(input_str, max_length=512, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "    device =  'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids[\"input_ids\"].to(device), attention_mask=input_ids[\"attention_mask\"].to(device))\n",
    "    return dict(zip([\"Fake\",\"Real\"], [x.item() for x in list(torch.nn.Softmax()(output.logits)[0])] ))\n",
    "\n",
    "@tool(\"internet_search\", return_direct=False)\n",
    "def internet_search(query: str) -> str:\n",
    "    \"\"\"Searches the internet using DuckDuckGo, focusing on Romanian sources.\"\"\"\n",
    "    with DDGS() as ddgs:\n",
    "        results = [r for r in ddgs.text(f\"{query} site:.ro\", max_results=5)]\n",
    "        return results if results else \"Niciun rezultat găsit.\"\n",
    "\n",
    "@tool(\"process_content\", return_direct=False)\n",
    "def process_content(url: str) -> str:\n",
    "    \"\"\"Processes content from a Romanian webpage.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    return soup.get_text()\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    next: str\n",
    "\n",
    "tools = [internet_search, process_content, detect_fake_news]\n",
    "\n",
    "def create_agent(llm, tools, system_prompt):\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ])\n",
    "    agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "    executor = AgentExecutor(agent=agent, tools=tools)\n",
    "    return executor\n",
    "\n",
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    processed_output = replace_unicode_chars(result[\"output\"])\n",
    "    return {\"messages\": [HumanMessage(content=processed_output, name=name)]}\n",
    "    #return {\"messages\": [HumanMessage(content=result[\"output\"], name=name)]}\n",
    "\n",
    "members = [\"Web_Searcher\", \"Insight_Researcher\"]\n",
    "system_prompt = (\n",
    "    \"As a supervisor, your role is to oversee a dialogue between these workers: {members}. \"\n",
    "    \"Based on the user's request, determine which worker should take the next action. \"\n",
    "    \"Each worker is responsible for executing a specific task and reporting back their findings and progress. \"\n",
    "    \"Once all tasks are complete, indicate with 'FINISH'.\"\n",
    ")\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "search_agent = create_agent(chat_model, tools, \"You are a web searcher. Search the internet for information and summarize it in english.\")\n",
    "search_node = functools.partial(agent_node, agent=search_agent, name=\"Web_Searcher\")\n",
    "insights_research_agent = create_agent(chat_model, tools, \"\"\"You are a Insight Researcher. Do step by step. \n",
    "        Based on the provided content first verify the authenticity of information and take into account the answer of the detect_fake_news tool,\n",
    "        then for a comprehensive assessment of the article's claims and to verify if the news is fake or not, cross-reference the events described with reports from established news organizations known for their journalistic standards\n",
    "        and finally find insights so you can say if the original news is fake or not.\n",
    "        search for more information on this topic from other sources to provide a balanced view.\n",
    "        Include the insights and sources with quotes in the final response.\n",
    "        \"\"\")\n",
    "\n",
    "insights_research_node = functools.partial(agent_node, agent=insights_research_agent, name=\"Insight_Researcher\")\n",
    "\n",
    "workflow.add_node(\"Web_Searcher\", search_node)\n",
    "workflow.add_node(\"Insight_Researcher\", insights_research_node)\n",
    "\n",
    "for member in members:\n",
    "    workflow.add_edge(member, \"supervisor\")\n",
    "\n",
    "conditional_map = {k: k for k in members}\n",
    "conditional_map[\"FINISH\"] = END\n",
    "workflow.add_conditional_edges(\"supervisor\", lambda x: x[\"next\"], conditional_map)\n",
    "workflow.set_entry_point(\"supervisor\")\n",
    "\n",
    "def run_graph(input_message):\n",
    "    response = graph.invoke({\n",
    "        \"messages\": [HumanMessage(content=input_message)]\n",
    "    })\n",
    "    processed_response = replace_unicode_chars(response['messages'][1].content)\n",
    "    return json.dumps(processed_response, indent=2)\n",
    "    \n",
    "\n",
    "inputs = gr.Textbox(lines=2, placeholder=\"Enter your query here...\")\n",
    "outputs = gr.Textbox()\n",
    "\n",
    "demo = gr.Interface(fn=run_graph, inputs=inputs, outputs=outputs)\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c392f4-bb56-43e1-a17b-9e22b81bfc17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
